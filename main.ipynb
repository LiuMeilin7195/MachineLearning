{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 个贷违约预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方案介绍\n",
    "1. 对于样本不平衡的问题，修改损失函数的权重，将负样本的权重设为0.2，正样本为1.0\n",
    "1. 对于连续数值型变量，对他们进行 均值-方差归一化\n",
    "1. 对于分类变量，在网络中进行重编码（即增加全连接层，用于模拟embedding）\n",
    "1. 本方案直接弃用了地区编码，时间等信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T08:07:35.496335Z",
     "iopub.status.busy": "2022-11-11T08:07:35.495170Z",
     "iopub.status.idle": "2022-11-11T08:07:35.556189Z",
     "shell.execute_reply": "2022-11-11T08:07:35.555275Z",
     "shell.execute_reply.started": "2022-11-11T08:07:35.496299Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_id', 'user_id', 'total_loan', 'year_of_loan', 'interest',\n",
      "       'monthly_payment', 'class', 'employer_type', 'industry', 'work_year',\n",
      "       'house_exist', 'censor_status', 'issue_date', 'use', 'post_code',\n",
      "       'region', 'debt_loan_ratio', 'del_in_18month', 'scoring_low',\n",
      "       'scoring_high', 'known_outstanding_loan', 'known_dero',\n",
      "       'pub_dero_bankrup', 'recircle_b', 'recircle_u', 'initial_list_status',\n",
      "       'app_type', 'earlies_credit_mon', 'title', 'policy_code', 'f0', 'f1',\n",
      "       'f2', 'f3', 'f4', 'early_return', 'early_return_amount',\n",
      "       'early_return_amount_3mon', 'isDefault'],\n",
      "      dtype='object')\n",
      "(10000, 39)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "import pandas as pd\n",
    "\n",
    "# 算力有限，只使用了train_public中的10000条数据作为训练集\n",
    "train_df=pd.read_csv('data/data130186/train_public.csv')\n",
    "\n",
    "# 展示列名\n",
    "print(train_df.columns)\n",
    "# 展示数据集大小\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T08:07:35.712318Z",
     "iopub.status.busy": "2022-11-11T08:07:35.711162Z",
     "iopub.status.idle": "2022-11-11T08:07:35.726131Z",
     "shell.execute_reply": "2022-11-11T08:07:35.725195Z",
     "shell.execute_reply.started": "2022-11-11T08:07:35.712279Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 飞桨的主库，paddle 根目录下保留了常用API的别名，当前包括：paddle.tensor、paddle.framework、paddle.device目录下的所有API\n",
    "import paddle\n",
    "import numpy as np\n",
    "\n",
    "class MyDateset(paddle.io.Dataset):\n",
    "    # csv_dir对应要读取的数据地址，standard_csv_dir用于生成均值和方差信息对数据进行归一化的文件地址\n",
    "    def __init__(self,csv_dir,standard_csv_dir='data/data130186/train_public.csv',mode = 'train'):\n",
    "        super(MyDateset, self).__init__()\n",
    "\n",
    "        # 读取数据\n",
    "        # csv_dir = 'data/data130186/train_public.csv'\n",
    "        self.df = pd.read_csv(csv_dir)\n",
    "        \n",
    "        # 构造各个变量的均值和方差\n",
    "        st_df = pd.read_csv(standard_csv_dir)\n",
    "        self.mean_df = st_df.mean()\n",
    "        self.std_df = st_df.std()\n",
    "\n",
    "        # 分别指定数值型变量/分类变量/不使用的变量\n",
    "        self.num_item = ['total_loan', 'year_of_loan', 'interest','monthly_payment',\n",
    "        'debt_loan_ratio', 'del_in_18month', 'scoring_low','scoring_high', 'known_outstanding_loan', 'known_dero','pub_dero_bankrup', 'recircle_b', 'recircle_u', \n",
    "        'f0', 'f1','f2', 'f3', 'f4', 'early_return', 'early_return_amount','early_return_amount_3mon']\n",
    "        self.un_num_item = ['class','employer_type','industry','work_year','house_exist', 'censor_status',\n",
    "        'use',\n",
    "        'initial_list_status','app_type',\n",
    "        'policy_code']\n",
    "        self.un_use_item = ['loan_id', 'user_id',\n",
    "        'issue_date', \n",
    "        'post_code', 'region',\n",
    "        'earlies_credit_mon','title']\n",
    "\n",
    "        # 构造一个映射表，将分类变量/分类字符串映射到对应数值上\n",
    "        un_num_item_list = {}\n",
    "        for item in self.un_num_item:\n",
    "            # list(set())的功能是对原列表去重并按从小到大排序\n",
    "            # 得到了每个类别变量的所有value，将其组成了列表\n",
    "            un_num_item_list[item]=list(set(st_df[item].values))\n",
    "        self.un_num_item_list = un_num_item_list\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data=[]\n",
    "\n",
    "        # 数值型变量\n",
    "        # 进行归一化，如果这个数值缺省了直接设置为0\n",
    "        for item in self.num_item:\n",
    "            if np.isnan(self.df[item][index]):\n",
    "                data.append((0-self.mean_df[item])/self.std_df[item])\n",
    "            else:\n",
    "                data.append((self.df[item][index]-self.mean_df[item])/self.std_df[item])\n",
    "        \n",
    "        emb_data = []\n",
    "\n",
    "        # 类别型变量\n",
    "        # 将分类变量映射到对应数值上\n",
    "        for item in self.un_num_item:\n",
    "            try:\n",
    "                # 如果该项的value不在列表中，则设置为-1\n",
    "                if self.df[item][index] not in self.un_num_item_list[item]:\n",
    "                    emb_data.append(-1)\n",
    "                else:\n",
    "                    # 否则设置为该value的下标值index\n",
    "                    emb_data.append(self.un_num_item_list[item].index(self.df[item][index]))\n",
    "            except:\n",
    "                emb_data.append(-1)\n",
    "\n",
    "        # 将数据转换为tensor类型，便于接下来的处理\n",
    "        data = paddle.to_tensor(data).astype('float32')\n",
    "        emb_data = paddle.to_tensor(emb_data).astype('float32')\n",
    "\n",
    "        # 如果当前模式不为train，则返回对应的loan_id，用于锁定样本条目\n",
    "        if self.mode == 'train':\n",
    "            label = self.df['isDefault'][index]\n",
    "        else:\n",
    "            label = self.df['loan_id'][index]\n",
    "\n",
    "        label = np.array(label).astype('int64')\n",
    "        return data,emb_data,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T08:07:35.728147Z",
     "iopub.status.busy": "2022-11-11T08:07:35.727822Z",
     "iopub.status.idle": "2022-11-11T08:07:35.924620Z",
     "shell.execute_reply": "2022-11-11T08:07:35.923529Z",
     "shell.execute_reply.started": "2022-11-11T08:07:35.728115Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Tensor(shape=[21], dtype=float32, place=Place(cpu), stop_gradient=True,\n",
      "       [ 1.94507027, -0.56161529, -0.36030969,  2.81924415, -1.06214857,\n",
      "        -0.35715219, -1.39864016, -1.26400948, -1.57160521, -0.37241074,\n",
      "        -0.36666167, -0.41815358,  1.46703112, -1.42198610, -0.03773430,\n",
      "        -0.61069232, -1.16881323, -0.84118545,  1.17932808,  2.56085277,\n",
      "        -0.52783436]), Tensor(shape=[10], dtype=float32, place=Place(cpu), stop_gradient=True,\n",
      "       [5. , 2. , 11., 5. , 0. , 1. , 2. , 0. , 0. , 0. ]), array(0))\n",
      "[21]\n",
      "[10]\n",
      "0\n",
      "Tensor(shape=[10], dtype=float32, place=Place(cpu), stop_gradient=True,\n",
      "       [5. , 2. , 11., 5. , 0. , 1. , 2. , 0. , 0. , 0. ])\n"
     ]
    }
   ],
   "source": [
    "# 训练模式\n",
    "dataset=MyDateset('data/data130186/train_public.csv')\n",
    "[data,emb_data,label] = dataset[0]\n",
    "print(dataset[0])\n",
    "print(data.shape)\n",
    "print(emb_data.shape)\n",
    "print(label)\n",
    "print(emb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T08:07:35.926634Z",
     "iopub.status.busy": "2022-11-11T08:07:35.926237Z",
     "iopub.status.idle": "2022-11-11T08:07:35.931123Z",
     "shell.execute_reply": "2022-11-11T08:07:35.930292Z",
     "shell.execute_reply.started": "2022-11-11T08:07:35.926606Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# paddle.nn：组网相关的API，包括 Linear、卷积 Conv2D、循环神经网络LSTM、损失函数CrossEntropyLoss、激活函数ReLU等\n",
    "# Linear：神经网络的全连接层函数，包含所有输入权重相加的基本神经元结构\n",
    "# class MyNet(paddle.nn.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(MyNet,self).__init__()\n",
    "#         # 输入维度是21，输出维度是512\n",
    "#         self.fc = paddle.nn.Linear(in_features=21, out_features=512)\n",
    "\n",
    "#         # 输入维度是10，输出维度是2048\n",
    "#         # 因为emb_data.shape=[10]\n",
    "#         self.emb1 = paddle.nn.Linear(in_features=10,out_features=2048)\n",
    "#         # 输入维度是2048，输出维度是512\n",
    "#         self.emb2 = paddle.nn.Linear(in_features=2048,out_features=512)\n",
    "\n",
    "#         # 输入维度是1024，输出维度是2\n",
    "#         self.out = paddle.nn.Linear(in_features=1024,out_features=2)\n",
    "\n",
    "#     def forward(self,data,emb_data):\n",
    "#         x = self.fc(data)\n",
    "#         # x.shape=[21]变为x.shape=[512]\n",
    "\n",
    "#         x = paddle.nn.functional.relu(x)\n",
    "\n",
    "#         emb = self.emb1(emb_data)\n",
    "#         # emb_data.shape=[10]变为emb_data.shape=[2048]\n",
    "#         emb = paddle.nn.functional.relu(emb)\n",
    "\n",
    "#         emb = self.emb2(emb)\n",
    "#         # emb_data.shape=[2048]变为emb_data.shape=[512]\n",
    "#         emb = paddle.nn.functional.relu(emb)\n",
    "\n",
    "#         # 对输入沿参数 axis 轴进行联结，返回一个新的 Tensor\n",
    "#         # 连结\n",
    "#         x = paddle.concat([x,emb],axis=-1)\n",
    "#         # concat[x,emb].shape=[512+512=1024]\n",
    "\n",
    "#         x = self.out(x)\n",
    "        \n",
    "#         x = paddle.nn.functional.sigmoid(x)\n",
    "#         # x = paddle.nn.functional.relu(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造更复杂的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T08:07:35.932292Z",
     "iopub.status.busy": "2022-11-11T08:07:35.932052Z",
     "iopub.status.idle": "2022-11-11T08:07:35.940828Z",
     "shell.execute_reply": "2022-11-11T08:07:35.940144Z",
     "shell.execute_reply.started": "2022-11-11T08:07:35.932269Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyNet(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyNet,self).__init__()\n",
    "        self.fc1 = paddle.nn.Linear(in_features=31, out_features=128)\n",
    "        self.Sigmoid1 = paddle.nn.Sigmoid()\n",
    "        self.dropout1 = paddle.nn.Dropout(p=0.2)\n",
    "        self.fc2 = paddle.nn.Linear(in_features=128, out_features=512)\n",
    "        self.Sigmoid2 = paddle.nn.Sigmoid()\n",
    "        self.dropout2 = paddle.nn.Dropout(p=0.3)\n",
    "        self.fc3 = paddle.nn.Linear(in_features=512, out_features=2048)\n",
    "        self.Sigmoid3 = paddle.nn.Sigmoid()\n",
    "        self.dropout3 = paddle.nn.Dropout(p=0.2)\n",
    "\n",
    "        self.fc4 = paddle.nn.Linear(in_features=2048, out_features=1024)\n",
    "        self.Sigmoid4 = paddle.nn.Sigmoid()\n",
    "        self.dropout4 = paddle.nn.Dropout(p=0.2)\n",
    "\n",
    "        self.out = paddle.nn.Linear(in_features=1024,out_features=2)\n",
    "\n",
    "    def forward(self,data,emb_data):\n",
    "\n",
    "        x = paddle.concat([data,emb_data],axis=-1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        #x = self.dropout1(x)\n",
    "        #x = self.Sigmoid1(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = self.dropout2(x)\n",
    "        #x = self.Sigmoid2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        #x = self.dropout3(x)\n",
    "        #x = self.Sigmoid3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        #x = self.Sigmoid4(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        \n",
    "        x = paddle.nn.functional.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T08:07:35.943150Z",
     "iopub.status.busy": "2022-11-11T08:07:35.942349Z",
     "iopub.status.idle": "2022-11-11T08:07:36.120664Z",
     "shell.execute_reply": "2022-11-11T08:07:36.119728Z",
     "shell.execute_reply.started": "2022-11-11T08:07:35.943123Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 构造读取器\n",
    "train_dataset=MyDateset('data/data130186/train_public.csv')\n",
    "\n",
    "train_dataloader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1000,\n",
    "    shuffle=True,\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T08:07:36.122287Z",
     "iopub.status.busy": "2022-11-11T08:07:36.121785Z",
     "iopub.status.idle": "2022-11-11T08:20:52.882057Z",
     "shell.execute_reply": "2022-11-11T08:20:52.880978Z",
     "shell.execute_reply.started": "2022-11-11T08:07:36.122258Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, Auc is:0.5499751871448442, loss is: [0.69469315]\n",
      "epoch: 0, batch: 1, Auc is:0.5517433456012897, loss is: [0.69435847]\n",
      "epoch: 0, batch: 2, Auc is:0.553727997412739, loss is: [0.6808947]\n",
      "epoch: 0, batch: 3, Auc is:0.562773089702137, loss is: [0.680034]\n",
      "epoch: 0, batch: 4, Auc is:0.5686370742145967, loss is: [0.6775569]\n",
      "epoch: 0, batch: 5, Auc is:0.5886830818152956, loss is: [0.6707368]\n",
      "epoch: 0, batch: 6, Auc is:0.5940370714375736, loss is: [0.6798332]\n",
      "epoch: 0, batch: 7, Auc is:0.6058022277917015, loss is: [0.66747534]\n",
      "epoch: 0, batch: 8, Auc is:0.6103651077784652, loss is: [0.6681505]\n",
      "epoch: 0, batch: 9, Auc is:0.6176003362312057, loss is: [0.6649606]\n",
      "epoch: 1, batch: 0, Auc is:0.6273525722939826, loss is: [0.6651412]\n",
      "epoch: 1, batch: 1, Auc is:0.6336310187465297, loss is: [0.6570655]\n",
      "epoch: 1, batch: 2, Auc is:0.6416815717042497, loss is: [0.6543868]\n",
      "epoch: 1, batch: 3, Auc is:0.6502967956321495, loss is: [0.6488952]\n",
      "epoch: 1, batch: 4, Auc is:0.6552567138108704, loss is: [0.6530469]\n",
      "epoch: 1, batch: 5, Auc is:0.6613052643694116, loss is: [0.65076774]\n",
      "epoch: 1, batch: 6, Auc is:0.6674572450687623, loss is: [0.6463354]\n",
      "epoch: 1, batch: 7, Auc is:0.6712270367637416, loss is: [0.64479685]\n",
      "epoch: 1, batch: 8, Auc is:0.6756451945883887, loss is: [0.64056027]\n",
      "epoch: 1, batch: 9, Auc is:0.679269943063449, loss is: [0.6453389]\n",
      "epoch: 2, batch: 0, Auc is:0.6857128225386847, loss is: [0.6315542]\n",
      "epoch: 2, batch: 1, Auc is:0.6917866492093288, loss is: [0.63036597]\n",
      "epoch: 2, batch: 2, Auc is:0.6938030248888745, loss is: [0.6403494]\n",
      "epoch: 2, batch: 3, Auc is:0.6969026625355135, loss is: [0.6334199]\n",
      "epoch: 2, batch: 4, Auc is:0.700888930421937, loss is: [0.6346755]\n",
      "epoch: 2, batch: 5, Auc is:0.7052923681346394, loss is: [0.62569636]\n",
      "epoch: 2, batch: 6, Auc is:0.7083758523374977, loss is: [0.62948096]\n",
      "epoch: 2, batch: 7, Auc is:0.7126955590587659, loss is: [0.6202789]\n",
      "epoch: 2, batch: 8, Auc is:0.7150213854708711, loss is: [0.63484913]\n",
      "epoch: 2, batch: 9, Auc is:0.718805273467706, loss is: [0.6229255]\n",
      "epoch: 3, batch: 0, Auc is:0.7215708824096259, loss is: [0.6198103]\n",
      "epoch: 3, batch: 1, Auc is:0.7240722745287559, loss is: [0.6185155]\n",
      "epoch: 3, batch: 2, Auc is:0.7276197055760301, loss is: [0.6168947]\n",
      "epoch: 3, batch: 3, Auc is:0.7306254604749672, loss is: [0.61407113]\n",
      "epoch: 3, batch: 4, Auc is:0.7333123528359593, loss is: [0.61596054]\n",
      "epoch: 3, batch: 5, Auc is:0.735628637885454, loss is: [0.61444306]\n",
      "epoch: 3, batch: 6, Auc is:0.738070452463634, loss is: [0.61420536]\n",
      "epoch: 3, batch: 7, Auc is:0.7405732950552778, loss is: [0.6149462]\n",
      "epoch: 3, batch: 8, Auc is:0.7424818007672908, loss is: [0.6103801]\n",
      "epoch: 3, batch: 9, Auc is:0.7447672661232415, loss is: [0.6094557]\n",
      "epoch: 4, batch: 0, Auc is:0.7463459956087809, loss is: [0.6154827]\n",
      "epoch: 4, batch: 1, Auc is:0.7490568760725295, loss is: [0.59593064]\n",
      "epoch: 4, batch: 2, Auc is:0.7511503028164689, loss is: [0.6012942]\n",
      "epoch: 4, batch: 3, Auc is:0.7533749349724932, loss is: [0.60498416]\n",
      "epoch: 4, batch: 4, Auc is:0.7552382800536318, loss is: [0.60532176]\n",
      "epoch: 4, batch: 5, Auc is:0.7567673515308071, loss is: [0.6047839]\n",
      "epoch: 4, batch: 6, Auc is:0.7581930181041605, loss is: [0.6042625]\n",
      "epoch: 4, batch: 7, Auc is:0.7595542915931806, loss is: [0.5992523]\n",
      "epoch: 4, batch: 8, Auc is:0.7611898951192528, loss is: [0.6019556]\n",
      "epoch: 4, batch: 9, Auc is:0.7633055276755989, loss is: [0.59262955]\n",
      "epoch: 5, batch: 0, Auc is:0.764697897540474, loss is: [0.60247344]\n",
      "epoch: 5, batch: 1, Auc is:0.7660919668964871, loss is: [0.59634775]\n",
      "epoch: 5, batch: 2, Auc is:0.7676388877158459, loss is: [0.59453446]\n",
      "epoch: 5, batch: 3, Auc is:0.7690927883619735, loss is: [0.59234977]\n",
      "epoch: 5, batch: 4, Auc is:0.7709506303791207, loss is: [0.5874218]\n",
      "epoch: 5, batch: 5, Auc is:0.7724160150990071, loss is: [0.5926684]\n",
      "epoch: 5, batch: 6, Auc is:0.7739742440233789, loss is: [0.582433]\n",
      "epoch: 5, batch: 7, Auc is:0.7743381712622193, loss is: [0.6034801]\n",
      "epoch: 5, batch: 8, Auc is:0.7757573987425409, loss is: [0.58359736]\n",
      "epoch: 5, batch: 9, Auc is:0.776774278933511, loss is: [0.59066474]\n",
      "epoch: 6, batch: 0, Auc is:0.7774362027966745, loss is: [0.5970688]\n",
      "epoch: 6, batch: 1, Auc is:0.778402511765679, loss is: [0.5889321]\n",
      "epoch: 6, batch: 2, Auc is:0.7796448201885839, loss is: [0.58458847]\n",
      "epoch: 6, batch: 3, Auc is:0.7807364508473942, loss is: [0.5852821]\n",
      "epoch: 6, batch: 4, Auc is:0.7819354810100679, loss is: [0.5795714]\n",
      "epoch: 6, batch: 5, Auc is:0.7833097509969615, loss is: [0.57838196]\n",
      "epoch: 6, batch: 6, Auc is:0.7842846809041538, loss is: [0.5793342]\n",
      "epoch: 6, batch: 7, Auc is:0.7850927985368727, loss is: [0.58626]\n",
      "epoch: 6, batch: 8, Auc is:0.7859475034685967, loss is: [0.5821666]\n",
      "epoch: 6, batch: 9, Auc is:0.7866542297908448, loss is: [0.58512765]\n",
      "epoch: 7, batch: 0, Auc is:0.7880207680328077, loss is: [0.5723369]\n",
      "epoch: 7, batch: 1, Auc is:0.7887752042631901, loss is: [0.5806642]\n",
      "epoch: 7, batch: 2, Auc is:0.7899646256224007, loss is: [0.5714066]\n",
      "epoch: 7, batch: 3, Auc is:0.790542012327736, loss is: [0.5783231]\n",
      "epoch: 7, batch: 4, Auc is:0.7913617630675351, loss is: [0.57685804]\n",
      "epoch: 7, batch: 5, Auc is:0.7921379154252048, loss is: [0.57716805]\n",
      "epoch: 7, batch: 6, Auc is:0.7927201674599188, loss is: [0.580663]\n",
      "epoch: 7, batch: 7, Auc is:0.7932660718792246, loss is: [0.5789617]\n",
      "epoch: 7, batch: 8, Auc is:0.7937092104185806, loss is: [0.58378035]\n",
      "epoch: 7, batch: 9, Auc is:0.7941745751485747, loss is: [0.5782407]\n",
      "epoch: 8, batch: 0, Auc is:0.7947422792029102, loss is: [0.5804593]\n",
      "epoch: 8, batch: 1, Auc is:0.795313315374025, loss is: [0.5743193]\n",
      "epoch: 8, batch: 2, Auc is:0.7958462788793138, loss is: [0.57515043]\n",
      "epoch: 8, batch: 3, Auc is:0.796651990216312, loss is: [0.56783175]\n",
      "epoch: 8, batch: 4, Auc is:0.7972940217086245, loss is: [0.5705707]\n",
      "epoch: 8, batch: 5, Auc is:0.7976212758422269, loss is: [0.5766138]\n",
      "epoch: 8, batch: 6, Auc is:0.798341657632864, loss is: [0.56825304]\n",
      "epoch: 8, batch: 7, Auc is:0.7989713128649986, loss is: [0.5696688]\n",
      "epoch: 8, batch: 8, Auc is:0.7995325741032984, loss is: [0.5709972]\n",
      "epoch: 8, batch: 9, Auc is:0.7999543421472363, loss is: [0.5728582]\n",
      "epoch: 9, batch: 0, Auc is:0.800363098535233, loss is: [0.57189614]\n",
      "epoch: 9, batch: 1, Auc is:0.800816380223481, loss is: [0.57163966]\n",
      "epoch: 9, batch: 2, Auc is:0.8011220343196519, loss is: [0.5735778]\n",
      "epoch: 9, batch: 3, Auc is:0.8016616649075226, loss is: [0.5683126]\n",
      "epoch: 9, batch: 4, Auc is:0.8020991984881761, loss is: [0.56949514]\n",
      "epoch: 9, batch: 5, Auc is:0.8026877676655065, loss is: [0.56139207]\n",
      "epoch: 9, batch: 6, Auc is:0.8033526222917494, loss is: [0.558792]\n",
      "epoch: 9, batch: 7, Auc is:0.8037293446876514, loss is: [0.57019526]\n",
      "epoch: 9, batch: 8, Auc is:0.8038938592347119, loss is: [0.57687217]\n",
      "epoch: 9, batch: 9, Auc is:0.8046717084201612, loss is: [0.55230176]\n",
      "epoch: 10, batch: 0, Auc is:0.805024330356121, loss is: [0.5653789]\n",
      "epoch: 10, batch: 1, Auc is:0.8056050237760051, loss is: [0.5577833]\n",
      "epoch: 10, batch: 2, Auc is:0.8059021038507206, loss is: [0.5698959]\n",
      "epoch: 10, batch: 3, Auc is:0.8060709251447461, loss is: [0.5747502]\n",
      "epoch: 10, batch: 4, Auc is:0.8066764479517139, loss is: [0.5533472]\n",
      "epoch: 10, batch: 5, Auc is:0.8071605348661448, loss is: [0.5590537]\n",
      "epoch: 10, batch: 6, Auc is:0.8074865572064774, loss is: [0.5638851]\n",
      "epoch: 10, batch: 7, Auc is:0.808136201458221, loss is: [0.5488995]\n",
      "epoch: 10, batch: 8, Auc is:0.8084369999661697, loss is: [0.5646487]\n",
      "epoch: 10, batch: 9, Auc is:0.8086179227574846, loss is: [0.5708392]\n",
      "epoch: 11, batch: 0, Auc is:0.8090016789059945, loss is: [0.5595129]\n",
      "epoch: 11, batch: 1, Auc is:0.8092259693124682, loss is: [0.56319445]\n",
      "epoch: 11, batch: 2, Auc is:0.8093004269715587, loss is: [0.57490325]\n",
      "epoch: 11, batch: 3, Auc is:0.8095030380584197, loss is: [0.5613395]\n",
      "epoch: 11, batch: 4, Auc is:0.8101053010456032, loss is: [0.54952586]\n",
      "epoch: 11, batch: 5, Auc is:0.8102933218555447, loss is: [0.55988234]\n",
      "epoch: 11, batch: 6, Auc is:0.8106510337640167, loss is: [0.5608053]\n",
      "epoch: 11, batch: 7, Auc is:0.8107861128880357, loss is: [0.5680794]\n",
      "epoch: 11, batch: 8, Auc is:0.8113952846406871, loss is: [0.5420201]\n",
      "epoch: 11, batch: 9, Auc is:0.8118899131126479, loss is: [0.5518211]\n",
      "epoch: 12, batch: 0, Auc is:0.8123025394679929, loss is: [0.5547639]\n",
      "epoch: 12, batch: 1, Auc is:0.8124645349547284, loss is: [0.55774164]\n",
      "epoch: 12, batch: 2, Auc is:0.8127510961497778, loss is: [0.55676675]\n",
      "epoch: 12, batch: 3, Auc is:0.8130074165538691, loss is: [0.5607036]\n",
      "epoch: 12, batch: 4, Auc is:0.8133096641446392, loss is: [0.5540942]\n",
      "epoch: 12, batch: 5, Auc is:0.8136578293744812, loss is: [0.5548511]\n",
      "epoch: 12, batch: 6, Auc is:0.8141373409236384, loss is: [0.5470751]\n",
      "epoch: 12, batch: 7, Auc is:0.8143715257371947, loss is: [0.5533532]\n",
      "epoch: 12, batch: 8, Auc is:0.8145819252193557, loss is: [0.55327684]\n",
      "epoch: 12, batch: 9, Auc is:0.8146238908318103, loss is: [0.5664521]\n",
      "epoch: 13, batch: 0, Auc is:0.8148324256177258, loss is: [0.5551083]\n",
      "epoch: 13, batch: 1, Auc is:0.8150102917451888, loss is: [0.55670357]\n",
      "epoch: 13, batch: 2, Auc is:0.8151711516891438, loss is: [0.5564196]\n",
      "epoch: 13, batch: 3, Auc is:0.81556116642234, loss is: [0.5440866]\n",
      "epoch: 13, batch: 4, Auc is:0.815792423486254, loss is: [0.5553048]\n",
      "epoch: 13, batch: 5, Auc is:0.8162440294626027, loss is: [0.53713375]\n",
      "epoch: 13, batch: 6, Auc is:0.816452232242648, loss is: [0.55400133]\n",
      "epoch: 13, batch: 7, Auc is:0.8166149502718161, loss is: [0.55802006]\n",
      "epoch: 13, batch: 8, Auc is:0.8165764583912293, loss is: [0.5697119]\n",
      "epoch: 13, batch: 9, Auc is:0.8169415949546097, loss is: [0.544115]\n",
      "epoch: 14, batch: 0, Auc is:0.8171034399948885, loss is: [0.55553573]\n",
      "epoch: 14, batch: 1, Auc is:0.8173723709301814, loss is: [0.5473331]\n",
      "epoch: 14, batch: 2, Auc is:0.8174621492052887, loss is: [0.5569239]\n",
      "epoch: 14, batch: 3, Auc is:0.8176004455819342, loss is: [0.55371296]\n",
      "epoch: 14, batch: 4, Auc is:0.8179458502530067, loss is: [0.5423139]\n",
      "epoch: 14, batch: 5, Auc is:0.8181751402445838, loss is: [0.54987985]\n",
      "epoch: 14, batch: 6, Auc is:0.8182994847353783, loss is: [0.55437136]\n",
      "epoch: 14, batch: 7, Auc is:0.8183384920521054, loss is: [0.558056]\n",
      "epoch: 14, batch: 8, Auc is:0.8187133556475666, loss is: [0.5400019]\n",
      "epoch: 14, batch: 9, Auc is:0.8189491982618275, loss is: [0.54759747]\n",
      "epoch: 15, batch: 0, Auc is:0.8189127976087794, loss is: [0.56326735]\n",
      "epoch: 15, batch: 1, Auc is:0.8191416460640822, loss is: [0.5480728]\n",
      "epoch: 15, batch: 2, Auc is:0.8193537470920486, loss is: [0.5443095]\n",
      "epoch: 15, batch: 3, Auc is:0.8196333652802628, loss is: [0.5420109]\n",
      "epoch: 15, batch: 4, Auc is:0.8197899628939862, loss is: [0.5481582]\n",
      "epoch: 15, batch: 5, Auc is:0.8197403299679498, loss is: [0.55843425]\n",
      "epoch: 15, batch: 6, Auc is:0.8200000705280514, loss is: [0.5426932]\n",
      "epoch: 15, batch: 7, Auc is:0.820365425488971, loss is: [0.5345517]\n",
      "epoch: 15, batch: 8, Auc is:0.8206581889830363, loss is: [0.5386251]\n",
      "epoch: 15, batch: 9, Auc is:0.820748354134844, loss is: [0.55802643]\n",
      "epoch: 16, batch: 0, Auc is:0.8208153234195288, loss is: [0.5551741]\n",
      "epoch: 16, batch: 1, Auc is:0.8211050723529726, loss is: [0.53889173]\n",
      "epoch: 16, batch: 2, Auc is:0.8213608546751576, loss is: [0.5388457]\n",
      "epoch: 16, batch: 3, Auc is:0.821626292162634, loss is: [0.53927207]\n",
      "epoch: 16, batch: 4, Auc is:0.8216352481217364, loss is: [0.55530435]\n",
      "epoch: 16, batch: 5, Auc is:0.8217621209797974, loss is: [0.54821074]\n",
      "epoch: 16, batch: 6, Auc is:0.8219474862338491, loss is: [0.543617]\n",
      "epoch: 16, batch: 7, Auc is:0.8221358180741688, loss is: [0.5417785]\n",
      "epoch: 16, batch: 8, Auc is:0.8221717634951063, loss is: [0.54974353]\n",
      "epoch: 16, batch: 9, Auc is:0.8223077569792532, loss is: [0.54938066]\n",
      "epoch: 17, batch: 0, Auc is:0.8226084341237746, loss is: [0.5326667]\n",
      "epoch: 17, batch: 1, Auc is:0.8229438171005754, loss is: [0.52666515]\n",
      "epoch: 17, batch: 2, Auc is:0.8230091341176927, loss is: [0.5490482]\n",
      "epoch: 17, batch: 3, Auc is:0.8229228459974365, loss is: [0.5644364]\n",
      "epoch: 17, batch: 4, Auc is:0.8229721202697572, loss is: [0.55161554]\n",
      "epoch: 17, batch: 5, Auc is:0.8231343121924004, loss is: [0.5416656]\n",
      "epoch: 17, batch: 6, Auc is:0.8232906595589126, loss is: [0.5408544]\n",
      "epoch: 17, batch: 7, Auc is:0.8234903864606683, loss is: [0.5392489]\n",
      "epoch: 17, batch: 8, Auc is:0.8235304465268648, loss is: [0.55106235]\n",
      "epoch: 17, batch: 9, Auc is:0.823695824286983, loss is: [0.5424504]\n",
      "epoch: 18, batch: 0, Auc is:0.8239220566298017, loss is: [0.5310571]\n",
      "epoch: 18, batch: 1, Auc is:0.8241329194013384, loss is: [0.53928596]\n",
      "epoch: 18, batch: 2, Auc is:0.8242635325389911, loss is: [0.538489]\n",
      "epoch: 18, batch: 3, Auc is:0.8243498244781784, loss is: [0.5431424]\n",
      "epoch: 18, batch: 4, Auc is:0.8242656379295487, loss is: [0.56163514]\n",
      "epoch: 18, batch: 5, Auc is:0.824304646898342, loss is: [0.55088276]\n",
      "epoch: 18, batch: 6, Auc is:0.8245540035274247, loss is: [0.5330718]\n",
      "epoch: 18, batch: 7, Auc is:0.8245502455949042, loss is: [0.5508567]\n",
      "epoch: 18, batch: 8, Auc is:0.8247835820964193, loss is: [0.5319675]\n",
      "epoch: 18, batch: 9, Auc is:0.8248907091856023, loss is: [0.5434443]\n",
      "epoch: 19, batch: 0, Auc is:0.8249463179308804, loss is: [0.54634756]\n",
      "epoch: 19, batch: 1, Auc is:0.8252179507953205, loss is: [0.5279457]\n",
      "epoch: 19, batch: 2, Auc is:0.8252591432503842, loss is: [0.54758763]\n",
      "epoch: 19, batch: 3, Auc is:0.8253492308634894, loss is: [0.54348737]\n",
      "epoch: 19, batch: 4, Auc is:0.8254419129185352, loss is: [0.544805]\n",
      "epoch: 19, batch: 5, Auc is:0.8255579905081725, loss is: [0.5376498]\n",
      "epoch: 19, batch: 6, Auc is:0.8255997185418046, loss is: [0.54793257]\n",
      "epoch: 19, batch: 7, Auc is:0.8257420410912691, loss is: [0.5375335]\n",
      "epoch: 19, batch: 8, Auc is:0.8258285399212804, loss is: [0.53944707]\n",
      "epoch: 19, batch: 9, Auc is:0.8260191211851879, loss is: [0.53165376]\n",
      "epoch: 20, batch: 0, Auc is:0.8260538667161673, loss is: [0.54646283]\n",
      "epoch: 20, batch: 1, Auc is:0.826206099518077, loss is: [0.5357086]\n",
      "epoch: 20, batch: 2, Auc is:0.8262109458123488, loss is: [0.54904914]\n",
      "epoch: 20, batch: 3, Auc is:0.8261768782121367, loss is: [0.5469713]\n",
      "epoch: 20, batch: 4, Auc is:0.8263079617298474, loss is: [0.53780895]\n",
      "epoch: 20, batch: 5, Auc is:0.8264265428188, loss is: [0.53760874]\n",
      "epoch: 20, batch: 6, Auc is:0.8265607882319197, loss is: [0.5347651]\n",
      "epoch: 20, batch: 7, Auc is:0.8267605010356627, loss is: [0.5308004]\n",
      "epoch: 20, batch: 8, Auc is:0.8267444295546437, loss is: [0.55298394]\n",
      "epoch: 20, batch: 9, Auc is:0.8270756684127563, loss is: [0.5151766]\n",
      "epoch: 21, batch: 0, Auc is:0.8271885808231031, loss is: [0.53211224]\n",
      "epoch: 21, batch: 1, Auc is:0.8271996635284907, loss is: [0.54705113]\n",
      "epoch: 21, batch: 2, Auc is:0.8273090325187015, loss is: [0.5357847]\n",
      "epoch: 21, batch: 3, Auc is:0.8274516533375886, loss is: [0.5352495]\n",
      "epoch: 21, batch: 4, Auc is:0.8276715602733173, loss is: [0.5246145]\n",
      "epoch: 21, batch: 5, Auc is:0.8275936310028718, loss is: [0.5554032]\n",
      "epoch: 21, batch: 6, Auc is:0.8276278315463675, loss is: [0.54594976]\n",
      "epoch: 21, batch: 7, Auc is:0.8278606942336002, loss is: [0.5209983]\n",
      "epoch: 21, batch: 8, Auc is:0.8279455368342988, loss is: [0.54013324]\n",
      "epoch: 21, batch: 9, Auc is:0.828031019863767, loss is: [0.53726554]\n",
      "epoch: 22, batch: 0, Auc is:0.8281266407117519, loss is: [0.53501076]\n",
      "epoch: 22, batch: 1, Auc is:0.8281181593944148, loss is: [0.5431204]\n",
      "epoch: 22, batch: 2, Auc is:0.8282809914546786, loss is: [0.5271636]\n",
      "epoch: 22, batch: 3, Auc is:0.8282940215778233, loss is: [0.54543936]\n",
      "epoch: 22, batch: 4, Auc is:0.8283889510881415, loss is: [0.5349413]\n",
      "epoch: 22, batch: 5, Auc is:0.828519521464035, loss is: [0.52925116]\n",
      "epoch: 22, batch: 6, Auc is:0.8285741640345156, loss is: [0.54256225]\n",
      "epoch: 22, batch: 7, Auc is:0.8285146358414374, loss is: [0.55255204]\n",
      "epoch: 22, batch: 8, Auc is:0.828667465533268, loss is: [0.5304473]\n",
      "epoch: 22, batch: 9, Auc is:0.8288861016852894, loss is: [0.52079284]\n",
      "epoch: 23, batch: 0, Auc is:0.8289100622088306, loss is: [0.5429721]\n",
      "epoch: 23, batch: 1, Auc is:0.8289926111488459, loss is: [0.53682846]\n",
      "epoch: 23, batch: 2, Auc is:0.8289837317755273, loss is: [0.54228896]\n",
      "epoch: 23, batch: 3, Auc is:0.8291775913254834, loss is: [0.52119154]\n",
      "epoch: 23, batch: 4, Auc is:0.8291756064705443, loss is: [0.5432763]\n",
      "epoch: 23, batch: 5, Auc is:0.8292357796478759, loss is: [0.53790045]\n",
      "epoch: 23, batch: 6, Auc is:0.829249106482226, loss is: [0.54193795]\n",
      "epoch: 23, batch: 7, Auc is:0.8294110475492361, loss is: [0.5247858]\n",
      "epoch: 23, batch: 8, Auc is:0.8295051658298093, loss is: [0.53334695]\n",
      "epoch: 23, batch: 9, Auc is:0.8296746576994614, loss is: [0.52447253]\n",
      "epoch: 24, batch: 0, Auc is:0.8298083927877609, loss is: [0.52666515]\n",
      "epoch: 24, batch: 1, Auc is:0.82975990413319, loss is: [0.55075514]\n",
      "epoch: 24, batch: 2, Auc is:0.8298607408882027, loss is: [0.53362286]\n",
      "epoch: 24, batch: 3, Auc is:0.8300344108553501, loss is: [0.52358633]\n",
      "epoch: 24, batch: 4, Auc is:0.8300723943888908, loss is: [0.5410546]\n",
      "epoch: 24, batch: 5, Auc is:0.8301275886244543, loss is: [0.53365636]\n",
      "epoch: 24, batch: 6, Auc is:0.8302261845018446, loss is: [0.5307065]\n",
      "epoch: 24, batch: 7, Auc is:0.8302931621116298, loss is: [0.5320075]\n",
      "epoch: 24, batch: 8, Auc is:0.8303890159306379, loss is: [0.530953]\n",
      "epoch: 24, batch: 9, Auc is:0.8304012189024177, loss is: [0.5374849]\n",
      "epoch: 25, batch: 0, Auc is:0.8305262092902951, loss is: [0.52419657]\n",
      "epoch: 25, batch: 1, Auc is:0.8305708359578493, loss is: [0.5320075]\n",
      "epoch: 25, batch: 2, Auc is:0.8307462508343203, loss is: [0.5188757]\n",
      "epoch: 25, batch: 3, Auc is:0.8307745275316011, loss is: [0.53835934]\n",
      "epoch: 25, batch: 4, Auc is:0.8308603499437612, loss is: [0.5266603]\n",
      "epoch: 25, batch: 5, Auc is:0.830901425175239, loss is: [0.53437984]\n",
      "epoch: 25, batch: 6, Auc is:0.8308945039534136, loss is: [0.54571044]\n",
      "epoch: 25, batch: 7, Auc is:0.8309769235020754, loss is: [0.534059]\n",
      "epoch: 25, batch: 8, Auc is:0.8310395215903985, loss is: [0.5378028]\n",
      "epoch: 25, batch: 9, Auc is:0.831081156882465, loss is: [0.53490794]\n",
      "epoch: 26, batch: 0, Auc is:0.8311766198245037, loss is: [0.5278729]\n",
      "epoch: 26, batch: 1, Auc is:0.8313902055994086, loss is: [0.5142538]\n",
      "epoch: 32, batch: 1, Auc is:0.8342379831199801, loss is: [0.5283162]\n",
      "epoch: 32, batch: 2, Auc is:0.8342563509999791, loss is: [0.5281284]\n",
      "epoch: 32, batch: 3, Auc is:0.8343402374219308, loss is: [0.52236265]\n",
      "epoch: 32, batch: 4, Auc is:0.834419739266741, loss is: [0.522011]\n",
      "epoch: 32, batch: 5, Auc is:0.8343947150121555, loss is: [0.54073066]\n",
      "epoch: 32, batch: 6, Auc is:0.8344443511793266, loss is: [0.525]\n",
      "epoch: 32, batch: 7, Auc is:0.8344841629502632, loss is: [0.5267238]\n",
      "epoch: 32, batch: 8, Auc is:0.8345932297931765, loss is: [0.5136075]\n",
      "epoch: 32, batch: 9, Auc is:0.8346336991124722, loss is: [0.52835613]\n",
      "epoch: 33, batch: 0, Auc is:0.8345875974233714, loss is: [0.5433055]\n",
      "epoch: 36, batch: 3, Auc is:0.8357759022374869, loss is: [0.5255908]\n",
      "epoch: 36, batch: 4, Auc is:0.8358159324293128, loss is: [0.52167714]\n",
      "epoch: 36, batch: 5, Auc is:0.8358528072477999, loss is: [0.5247039]\n",
      "epoch: 36, batch: 6, Auc is:0.8358955325871671, loss is: [0.52478755]\n",
      "epoch: 36, batch: 7, Auc is:0.835863385452757, loss is: [0.54057246]\n",
      "epoch: 36, batch: 8, Auc is:0.8359426039143273, loss is: [0.51172185]\n",
      "epoch: 36, batch: 9, Auc is:0.8360955607478666, loss is: [0.49879226]\n",
      "epoch: 37, batch: 0, Auc is:0.8362104735053664, loss is: [0.50626767]\n",
      "epoch: 37, batch: 1, Auc is:0.8362874279373698, loss is: [0.515366]\n",
      "epoch: 37, batch: 2, Auc is:0.8362228560129606, loss is: [0.54795086]\n",
      "epoch: 37, batch: 3, Auc is:0.8362489803102372, loss is: [0.526483]\n",
      "epoch: 37, batch: 4, Auc is:0.8362654821300449, loss is: [0.5285147]\n",
      "epoch: 37, batch: 5, Auc is:0.8362879306167714, loss is: [0.5268094]\n",
      "epoch: 37, batch: 6, Auc is:0.8363238691832865, loss is: [0.52360743]\n",
      "epoch: 37, batch: 7, Auc is:0.8363910009303872, loss is: [0.5175369]\n",
      "epoch: 37, batch: 8, Auc is:0.8364137551202439, loss is: [0.5232412]\n",
      "epoch: 37, batch: 9, Auc is:0.8364559401057394, loss is: [0.5173972]\n",
      "epoch: 38, batch: 0, Auc is:0.8364823289255326, loss is: [0.52451485]\n",
      "epoch: 38, batch: 1, Auc is:0.836583999539164, loss is: [0.50888765]\n",
      "epoch: 38, batch: 2, Auc is:0.836668125309481, loss is: [0.5098501]\n",
      "epoch: 38, batch: 3, Auc is:0.8366172818175809, loss is: [0.5409972]\n",
      "epoch: 38, batch: 4, Auc is:0.8366407610897773, loss is: [0.5245737]\n",
      "epoch: 38, batch: 5, Auc is:0.8366823835320134, loss is: [0.5190862]\n",
      "epoch: 38, batch: 6, Auc is:0.8366762486841305, loss is: [0.53355044]\n",
      "epoch: 38, batch: 7, Auc is:0.8366774393693278, loss is: [0.5303995]\n",
      "epoch: 38, batch: 8, Auc is:0.8366932047919101, loss is: [0.52552253]\n",
      "epoch: 38, batch: 9, Auc is:0.836748097539611, loss is: [0.5162727]\n",
      "epoch: 39, batch: 0, Auc is:0.8367402240857444, loss is: [0.5283903]\n",
      "epoch: 39, batch: 1, Auc is:0.8368237824547522, loss is: [0.5097162]\n",
      "epoch: 39, batch: 2, Auc is:0.8369166180112605, loss is: [0.5100107]\n",
      "epoch: 39, batch: 3, Auc is:0.8369279948310396, loss is: [0.5250414]\n",
      "epoch: 39, batch: 4, Auc is:0.8368811194513653, loss is: [0.5366714]\n",
      "epoch: 39, batch: 5, Auc is:0.8368581258025932, loss is: [0.53175825]\n",
      "epoch: 39, batch: 6, Auc is:0.836907455257052, loss is: [0.5201498]\n",
      "epoch: 39, batch: 7, Auc is:0.8369670870499373, loss is: [0.51693076]\n",
      "epoch: 39, batch: 8, Auc is:0.8369695038133068, loss is: [0.526921]\n",
      "epoch: 39, batch: 9, Auc is:0.8370297409928807, loss is: [0.5197642]\n",
      "epoch: 40, batch: 0, Auc is:0.8370317983094739, loss is: [0.5281061]\n",
      "epoch: 40, batch: 1, Auc is:0.8370641609311266, loss is: [0.5213986]\n",
      "epoch: 40, batch: 2, Auc is:0.8371046473279726, loss is: [0.51789564]\n",
      "epoch: 40, batch: 3, Auc is:0.8370961451626632, loss is: [0.52853674]\n",
      "epoch: 40, batch: 4, Auc is:0.8370794368355757, loss is: [0.5342552]\n",
      "epoch: 40, batch: 5, Auc is:0.8371357859902494, loss is: [0.5180039]\n",
      "epoch: 40, batch: 6, Auc is:0.8371690579034388, loss is: [0.5197771]\n",
      "epoch: 40, batch: 7, Auc is:0.8372198124965381, loss is: [0.52000624]\n",
      "epoch: 40, batch: 8, Auc is:0.8372535264721043, loss is: [0.52103555]\n",
      "epoch: 40, batch: 9, Auc is:0.8373219106998498, loss is: [0.51486194]\n",
      "epoch: 41, batch: 0, Auc is:0.8373740114940035, loss is: [0.5167173]\n",
      "epoch: 41, batch: 1, Auc is:0.8373322079999462, loss is: [0.53703415]\n",
      "epoch: 41, batch: 2, Auc is:0.8373558257613244, loss is: [0.5189606]\n",
      "epoch: 41, batch: 3, Auc is:0.8374124647121479, loss is: [0.5132978]\n",
      "epoch: 41, batch: 4, Auc is:0.8373586912877908, loss is: [0.5406883]\n",
      "epoch: 41, batch: 5, Auc is:0.8374221724072708, loss is: [0.5121355]\n",
      "epoch: 41, batch: 6, Auc is:0.8375197859889495, loss is: [0.50410247]\n",
      "epoch: 41, batch: 7, Auc is:0.8375305704160777, loss is: [0.5291849]\n",
      "epoch: 41, batch: 8, Auc is:0.8375826324761866, loss is: [0.51791054]\n",
      "epoch: 41, batch: 9, Auc is:0.8375945364723623, loss is: [0.5259489]\n",
      "epoch: 42, batch: 0, Auc is:0.8376365999350592, loss is: [0.5209051]\n",
      "epoch: 42, batch: 1, Auc is:0.8376794241344204, loss is: [0.5191859]\n",
      "epoch: 42, batch: 2, Auc is:0.8376844473106615, loss is: [0.525452]\n",
      "epoch: 42, batch: 3, Auc is:0.8377625013077821, loss is: [0.5070397]\n",
      "epoch: 42, batch: 4, Auc is:0.8378550046428604, loss is: [0.5051066]\n",
      "epoch: 42, batch: 5, Auc is:0.8378501564866095, loss is: [0.52587724]\n",
      "epoch: 42, batch: 6, Auc is:0.837834235454864, loss is: [0.5315701]\n",
      "epoch: 42, batch: 7, Auc is:0.8378945292221608, loss is: [0.51254004]\n",
      "epoch: 42, batch: 8, Auc is:0.8379051899641697, loss is: [0.5264823]\n",
      "epoch: 42, batch: 9, Auc is:0.8378509956415032, loss is: [0.54057366]\n",
      "epoch: 43, batch: 0, Auc is:0.837926130173509, loss is: [0.5116978]\n",
      "epoch: 43, batch: 1, Auc is:0.8379080043360599, loss is: [0.528462]\n",
      "epoch: 43, batch: 2, Auc is:0.8379634256313296, loss is: [0.5177109]\n",
      "epoch: 43, batch: 3, Auc is:0.8379851395211099, loss is: [0.52399975]\n",
      "epoch: 43, batch: 4, Auc is:0.8380255126547815, loss is: [0.51582575]\n",
      "epoch: 43, batch: 5, Auc is:0.8380406495788928, loss is: [0.5225438]\n",
      "epoch: 43, batch: 6, Auc is:0.8380069548493347, loss is: [0.5330812]\n",
      "epoch: 43, batch: 7, Auc is:0.8380503281158871, loss is: [0.5144054]\n",
      "epoch: 43, batch: 8, Auc is:0.838106756974547, loss is: [0.5098851]\n",
      "epoch: 43, batch: 9, Auc is:0.8380964062870927, loss is: [0.5308552]\n",
      "epoch: 44, batch: 0, Auc is:0.8380877720873143, loss is: [0.53003526]\n",
      "epoch: 44, batch: 1, Auc is:0.8381713107980159, loss is: [0.50615597]\n",
      "epoch: 44, batch: 2, Auc is:0.8381999992718786, loss is: [0.5184789]\n",
      "epoch: 44, batch: 3, Auc is:0.8382511726926303, loss is: [0.51256067]\n",
      "epoch: 44, batch: 4, Auc is:0.8383051187802646, loss is: [0.50851524]\n",
      "epoch: 44, batch: 5, Auc is:0.8383145539810949, loss is: [0.5231311]\n",
      "epoch: 44, batch: 6, Auc is:0.8383153263564291, loss is: [0.5278078]\n",
      "epoch: 44, batch: 7, Auc is:0.8382513645496741, loss is: [0.5420694]\n",
      "epoch: 44, batch: 8, Auc is:0.8383417742234771, loss is: [0.507024]\n",
      "epoch: 44, batch: 9, Auc is:0.8383280691390573, loss is: [0.53177816]\n",
      "epoch: 45, batch: 0, Auc is:0.8383796395258644, loss is: [0.50987905]\n",
      "epoch: 45, batch: 1, Auc is:0.8384198427355326, loss is: [0.51346403]\n",
      "epoch: 45, batch: 2, Auc is:0.8383987409107895, loss is: [0.5324435]\n",
      "epoch: 45, batch: 3, Auc is:0.8384580132880755, loss is: [0.5090859]\n",
      "epoch: 45, batch: 4, Auc is:0.8385100834821712, loss is: [0.5101112]\n",
      "epoch: 45, batch: 5, Auc is:0.8383902374259826, loss is: [0.5551813]\n",
      "epoch: 45, batch: 6, Auc is:0.8384493315992404, loss is: [0.5134983]\n",
      "epoch: 45, batch: 7, Auc is:0.8385107853528909, loss is: [0.5111762]\n",
      "epoch: 45, batch: 8, Auc is:0.8385325250843226, loss is: [0.5253083]\n",
      "epoch: 45, batch: 9, Auc is:0.8385564020769704, loss is: [0.51843673]\n",
      "epoch: 46, batch: 0, Auc is:0.8385674907318864, loss is: [0.5195478]\n",
      "epoch: 46, batch: 1, Auc is:0.8386429981612309, loss is: [0.50678736]\n",
      "epoch: 46, batch: 2, Auc is:0.8387140255519203, loss is: [0.50442624]\n",
      "epoch: 46, batch: 3, Auc is:0.8386840610046639, loss is: [0.5341398]\n",
      "epoch: 46, batch: 4, Auc is:0.8387227836068976, loss is: [0.51760054]\n",
      "epoch: 46, batch: 5, Auc is:0.8387083847689832, loss is: [0.53599435]\n",
      "epoch: 46, batch: 6, Auc is:0.838727500431768, loss is: [0.52014375]\n",
      "epoch: 46, batch: 7, Auc is:0.8387261281347391, loss is: [0.5243825]\n",
      "epoch: 46, batch: 8, Auc is:0.8387258507684798, loss is: [0.5227942]\n",
      "epoch: 46, batch: 9, Auc is:0.8387753919420148, loss is: [0.5111958]\n",
      "epoch: 47, batch: 0, Auc is:0.8387496957077429, loss is: [0.5302174]\n",
      "epoch: 47, batch: 1, Auc is:0.8387821266942033, loss is: [0.5167703]\n",
      "epoch: 47, batch: 2, Auc is:0.8388163466999395, loss is: [0.5140971]\n",
      "epoch: 47, batch: 3, Auc is:0.8388178141460474, loss is: [0.52477777]\n",
      "epoch: 47, batch: 4, Auc is:0.8388579034396556, loss is: [0.5152671]\n",
      "epoch: 47, batch: 5, Auc is:0.8388895158409904, loss is: [0.51696116]\n",
      "epoch: 47, batch: 6, Auc is:0.8389919672073565, loss is: [0.4972923]\n",
      "epoch: 47, batch: 7, Auc is:0.8389890533698918, loss is: [0.5241105]\n",
      "epoch: 47, batch: 8, Auc is:0.838999034232308, loss is: [0.5223507]\n",
      "epoch: 47, batch: 9, Auc is:0.8389891665816614, loss is: [0.5285388]\n",
      "epoch: 48, batch: 0, Auc is:0.8390092396939532, loss is: [0.5204212]\n",
      "epoch: 48, batch: 1, Auc is:0.8390205372990918, loss is: [0.5262795]\n",
      "epoch: 48, batch: 2, Auc is:0.839041252394925, loss is: [0.51237893]\n",
      "epoch: 48, batch: 3, Auc is:0.8390794247038196, loss is: [0.51525897]\n",
      "epoch: 48, batch: 4, Auc is:0.8390844572461634, loss is: [0.5232904]\n",
      "epoch: 48, batch: 5, Auc is:0.8390669344811582, loss is: [0.52843785]\n",
      "epoch: 48, batch: 6, Auc is:0.8390773710912584, loss is: [0.520534]\n",
      "epoch: 48, batch: 7, Auc is:0.8391258557559192, loss is: [0.5083626]\n",
      "epoch: 48, batch: 8, Auc is:0.8391593957350466, loss is: [0.51582533]\n",
      "epoch: 48, batch: 9, Auc is:0.8391751452327749, loss is: [0.521174]\n",
      "epoch: 49, batch: 0, Auc is:0.8392080251303478, loss is: [0.5182503]\n",
      "epoch: 49, batch: 1, Auc is:0.8392440870357155, loss is: [0.51303065]\n",
      "epoch: 49, batch: 2, Auc is:0.8392793381037419, loss is: [0.5129161]\n",
      "epoch: 49, batch: 3, Auc is:0.8392598068555218, loss is: [0.5282425]\n",
      "epoch: 49, batch: 4, Auc is:0.8392817984866987, loss is: [0.51649237]\n",
      "epoch: 49, batch: 5, Auc is:0.839286931618026, loss is: [0.52068335]\n",
      "epoch: 49, batch: 6, Auc is:0.8393078605689331, loss is: [0.51978517]\n",
      "epoch: 49, batch: 7, Auc is:0.8393627832326545, loss is: [0.5060198]\n",
      "epoch: 49, batch: 8, Auc is:0.8393805838800139, loss is: [0.5207159]\n",
      "epoch: 49, batch: 9, Auc is:0.8393520919397741, loss is: [0.5338667]\n",
      "epoch: 50, batch: 0, Auc is:0.8393681306710948, loss is: [0.51950693]\n",
      "epoch: 50, batch: 1, Auc is:0.8393610799728292, loss is: [0.5256527]\n",
      "epoch: 50, batch: 2, Auc is:0.8394169138867094, loss is: [0.5066015]\n",
      "epoch: 50, batch: 3, Auc is:0.8394015983509635, loss is: [0.5259607]\n",
      "epoch: 50, batch: 4, Auc is:0.8393708785109042, loss is: [0.5296711]\n",
      "epoch: 50, batch: 5, Auc is:0.8393809218063616, loss is: [0.52071434]\n",
      "epoch: 50, batch: 6, Auc is:0.8394152586219524, loss is: [0.5119956]\n",
      "epoch: 50, batch: 7, Auc is:0.8394467849218582, loss is: [0.51781994]\n",
      "epoch: 50, batch: 8, Auc is:0.8394863452142725, loss is: [0.5125542]\n",
      "epoch: 50, batch: 9, Auc is:0.8395415163697443, loss is: [0.5109545]\n",
      "epoch: 51, batch: 0, Auc is:0.8395219307614216, loss is: [0.5287205]\n",
      "epoch: 51, batch: 1, Auc is:0.8395601843292819, loss is: [0.5081182]\n",
      "epoch: 51, batch: 2, Auc is:0.8395931674709463, loss is: [0.5131769]\n",
      "epoch: 51, batch: 3, Auc is:0.8396314530826087, loss is: [0.5107462]\n",
      "epoch: 51, batch: 4, Auc is:0.8397042140260536, loss is: [0.5036227]\n",
      "epoch: 51, batch: 5, Auc is:0.8397098134957311, loss is: [0.5206736]\n",
      "epoch: 51, batch: 6, Auc is:0.8397739941477894, loss is: [0.50548965]\n",
      "epoch: 51, batch: 7, Auc is:0.8397443568294608, loss is: [0.53487444]\n",
      "epoch: 51, batch: 8, Auc is:0.8397650876271402, loss is: [0.5193242]\n",
      "epoch: 51, batch: 9, Auc is:0.8397192234742736, loss is: [0.5378283]\n",
      "epoch: 52, batch: 0, Auc is:0.8398065497747423, loss is: [0.49506617]\n",
      "epoch: 52, batch: 1, Auc is:0.8398401660698128, loss is: [0.51051146]\n",
      "epoch: 52, batch: 2, Auc is:0.8398669104095512, loss is: [0.51565343]\n",
      "epoch: 52, batch: 3, Auc is:0.83984115943786, loss is: [0.53777045]\n",
      "epoch: 52, batch: 4, Auc is:0.8398480850512088, loss is: [0.51878697]\n",
      "epoch: 52, batch: 5, Auc is:0.8398678423618807, loss is: [0.5149648]\n",
      "epoch: 52, batch: 6, Auc is:0.8398589630328835, loss is: [0.5239521]\n",
      "epoch: 52, batch: 7, Auc is:0.8398948080297581, loss is: [0.51455545]\n",
      "epoch: 52, batch: 8, Auc is:0.8398846129669065, loss is: [0.5261941]\n",
      "epoch: 52, batch: 9, Auc is:0.8398885753904182, loss is: [0.52199095]\n",
      "epoch: 53, batch: 0, Auc is:0.839960611395169, loss is: [0.49809185]\n",
      "epoch: 53, batch: 1, Auc is:0.839891201617971, loss is: [0.5443899]\n",
      "epoch: 53, batch: 2, Auc is:0.839993226311323, loss is: [0.4885597]\n",
      "epoch: 53, batch: 3, Auc is:0.8399853216277923, loss is: [0.5244237]\n",
      "epoch: 53, batch: 4, Auc is:0.8399918386032701, loss is: [0.52030367]\n",
      "epoch: 53, batch: 5, Auc is:0.8399423258750711, loss is: [0.53637326]\n",
      "epoch: 53, batch: 6, Auc is:0.8399672979652664, loss is: [0.5133225]\n",
      "epoch: 53, batch: 7, Auc is:0.8399972751802476, loss is: [0.5142811]\n",
      "epoch: 53, batch: 8, Auc is:0.8400202616229239, loss is: [0.5161662]\n",
      "epoch: 53, batch: 9, Auc is:0.8400500107812672, loss is: [0.517497]\n",
      "epoch: 54, batch: 0, Auc is:0.8400333277592431, loss is: [0.5267601]\n",
      "epoch: 54, batch: 1, Auc is:0.8399570127729749, loss is: [0.54500335]\n",
      "epoch: 54, batch: 2, Auc is:0.839937576251008, loss is: [0.525571]\n",
      "epoch: 54, batch: 3, Auc is:0.8399730818006794, loss is: [0.50962913]\n",
      "epoch: 54, batch: 4, Auc is:0.8399894596838825, loss is: [0.51770526]\n",
      "epoch: 54, batch: 5, Auc is:0.8400384136002554, loss is: [0.5098297]\n",
      "epoch: 54, batch: 6, Auc is:0.8400811895197524, loss is: [0.5072301]\n",
      "epoch: 54, batch: 7, Auc is:0.8401519681599211, loss is: [0.50222135]\n",
      "epoch: 54, batch: 8, Auc is:0.840175533561108, loss is: [0.51201254]\n",
      "epoch: 54, batch: 9, Auc is:0.8402134913205239, loss is: [0.512316]\n",
      "epoch: 55, batch: 0, Auc is:0.8403028683574728, loss is: [0.49025863]\n",
      "epoch: 55, batch: 1, Auc is:0.8403038703312244, loss is: [0.51643574]\n",
      "epoch: 55, batch: 2, Auc is:0.840315348991453, loss is: [0.51671296]\n",
      "epoch: 55, batch: 3, Auc is:0.8402876511184847, loss is: [0.52594924]\n",
      "epoch: 55, batch: 4, Auc is:0.8402470521556107, loss is: [0.53362715]\n",
      "epoch: 55, batch: 5, Auc is:0.8403139526692294, loss is: [0.50249237]\n",
      "epoch: 55, batch: 6, Auc is:0.8402868463070932, loss is: [0.52974796]\n",
      "epoch: 55, batch: 7, Auc is:0.8403086756216497, loss is: [0.51826376]\n",
      "epoch: 55, batch: 8, Auc is:0.8403851095846647, loss is: [0.50107765]\n",
      "epoch: 55, batch: 9, Auc is:0.8403652670133276, loss is: [0.5306808]\n",
      "epoch: 56, batch: 0, Auc is:0.8403658883523709, loss is: [0.5211766]\n",
      "epoch: 56, batch: 1, Auc is:0.8404011187943052, loss is: [0.512113]\n",
      "epoch: 56, batch: 2, Auc is:0.840452348768371, loss is: [0.5072497]\n",
      "epoch: 56, batch: 3, Auc is:0.8404923097183403, loss is: [0.5059622]\n",
      "epoch: 56, batch: 4, Auc is:0.8404924405181082, loss is: [0.5206647]\n",
      "epoch: 56, batch: 5, Auc is:0.8405232970395107, loss is: [0.51174957]\n",
      "epoch: 56, batch: 6, Auc is:0.8405326248863122, loss is: [0.5190408]\n",
      "epoch: 56, batch: 7, Auc is:0.8405089962796056, loss is: [0.5310471]\n",
      "epoch: 56, batch: 8, Auc is:0.8405072046624543, loss is: [0.51968205]\n",
      "epoch: 56, batch: 9, Auc is:0.8405105819415674, loss is: [0.518195]\n",
      "epoch: 57, batch: 0, Auc is:0.8404980837716508, loss is: [0.52370644]\n",
      "epoch: 57, batch: 1, Auc is:0.8404938143806893, loss is: [0.5223941]\n",
      "epoch: 57, batch: 2, Auc is:0.8404841848271125, loss is: [0.5246848]\n",
      "epoch: 57, batch: 3, Auc is:0.8404808305478162, loss is: [0.5261956]\n",
      "epoch: 57, batch: 4, Auc is:0.8405187555009209, loss is: [0.51042795]\n",
      "epoch: 57, batch: 5, Auc is:0.840591169568954, loss is: [0.4984275]\n",
      "epoch: 57, batch: 6, Auc is:0.8406081420043666, loss is: [0.51670766]\n",
      "epoch: 57, batch: 7, Auc is:0.8405796917346673, loss is: [0.5277343]\n",
      "epoch: 57, batch: 8, Auc is:0.8406577814432693, loss is: [0.49337408]\n",
      "epoch: 57, batch: 9, Auc is:0.8406609333410953, loss is: [0.5199645]\n",
      "epoch: 58, batch: 0, Auc is:0.8406891443616196, loss is: [0.5102803]\n",
      "epoch: 58, batch: 1, Auc is:0.8407096129809927, loss is: [0.51255494]\n",
      "epoch: 58, batch: 2, Auc is:0.8407210318519426, loss is: [0.5204696]\n",
      "epoch: 58, batch: 3, Auc is:0.8407661847610569, loss is: [0.5056398]\n",
      "epoch: 58, batch: 4, Auc is:0.8407782064425698, loss is: [0.5125804]\n",
      "epoch: 58, batch: 5, Auc is:0.8408079667134619, loss is: [0.51094085]\n",
      "epoch: 58, batch: 6, Auc is:0.8408110561691785, loss is: [0.5160746]\n",
      "epoch: 58, batch: 7, Auc is:0.8408401425475777, loss is: [0.5107052]\n",
      "epoch: 58, batch: 8, Auc is:0.8408088728954953, loss is: [0.5333211]\n",
      "epoch: 58, batch: 9, Auc is:0.8408035249408632, loss is: [0.5259913]\n",
      "epoch: 59, batch: 0, Auc is:0.8408240977596292, loss is: [0.50945985]\n",
      "epoch: 59, batch: 1, Auc is:0.8408189907721241, loss is: [0.5211085]\n",
      "epoch: 59, batch: 2, Auc is:0.8408260027426624, loss is: [0.5190962]\n",
      "epoch: 59, batch: 3, Auc is:0.8408484401590565, loss is: [0.51304555]\n",
      "epoch: 59, batch: 4, Auc is:0.8408808864585999, loss is: [0.50823987]\n",
      "epoch: 59, batch: 5, Auc is:0.8409083447920175, loss is: [0.50819826]\n",
      "epoch: 59, batch: 6, Auc is:0.8409484342842434, loss is: [0.5052575]\n",
      "epoch: 59, batch: 7, Auc is:0.8409277892841868, loss is: [0.53081375]\n",
      "epoch: 59, batch: 8, Auc is:0.8409455117957318, loss is: [0.5188613]\n",
      "epoch: 59, batch: 9, Auc is:0.8409400876301826, loss is: [0.52132785]\n",
      "epoch: 60, batch: 0, Auc is:0.8409589827021178, loss is: [0.51462716]\n",
      "epoch: 60, batch: 1, Auc is:0.8410013939963875, loss is: [0.50549936]\n",
      "epoch: 60, batch: 2, Auc is:0.8410428333122674, loss is: [0.5069163]\n",
      "epoch: 60, batch: 3, Auc is:0.8410550815949583, loss is: [0.51842445]\n",
      "epoch: 60, batch: 4, Auc is:0.8410332745692293, loss is: [0.5275922]\n",
      "epoch: 60, batch: 5, Auc is:0.8410937121918095, loss is: [0.49783865]\n",
      "epoch: 60, batch: 6, Auc is:0.8410721647081912, loss is: [0.5275958]\n",
      "epoch: 60, batch: 7, Auc is:0.8410976089185553, loss is: [0.50853544]\n",
      "epoch: 60, batch: 8, Auc is:0.841093960282371, loss is: [0.5160778]\n",
      "epoch: 60, batch: 9, Auc is:0.8410719517970502, loss is: [0.5309356]\n",
      "epoch: 61, batch: 0, Auc is:0.8410838648840193, loss is: [0.51567435]\n",
      "epoch: 61, batch: 1, Auc is:0.8410682049732227, loss is: [0.526513]\n",
      "epoch: 61, batch: 2, Auc is:0.8410696566793571, loss is: [0.51978356]\n",
      "epoch: 61, batch: 3, Auc is:0.8410872477531867, loss is: [0.5136755]\n",
      "epoch: 61, batch: 4, Auc is:0.8410803779201487, loss is: [0.5227394]\n",
      "epoch: 61, batch: 5, Auc is:0.8410886470946984, loss is: [0.5137618]\n",
      "epoch: 61, batch: 6, Auc is:0.8410646309411018, loss is: [0.5265158]\n",
      "epoch: 61, batch: 7, Auc is:0.8410981263545569, loss is: [0.50206804]\n",
      "epoch: 61, batch: 8, Auc is:0.8411416883441628, loss is: [0.50571626]\n",
      "epoch: 61, batch: 9, Auc is:0.8411928576420237, loss is: [0.50585955]\n",
      "epoch: 62, batch: 0, Auc is:0.8412106342714801, loss is: [0.5172994]\n",
      "epoch: 62, batch: 1, Auc is:0.8412910745465879, loss is: [0.48983237]\n",
      "epoch: 62, batch: 2, Auc is:0.8412974685635871, loss is: [0.51543325]\n",
      "epoch: 62, batch: 3, Auc is:0.841324725571154, loss is: [0.50937563]\n",
      "epoch: 62, batch: 4, Auc is:0.841311596032033, loss is: [0.5277525]\n",
      "epoch: 62, batch: 5, Auc is:0.8412538378876142, loss is: [0.5413514]\n",
      "epoch: 62, batch: 6, Auc is:0.8412498593979942, loss is: [0.5180181]\n",
      "epoch: 62, batch: 7, Auc is:0.8412894285705094, loss is: [0.5070177]\n",
      "epoch: 62, batch: 8, Auc is:0.8412607327683853, loss is: [0.5292997]\n",
      "epoch: 62, batch: 9, Auc is:0.8413269088968436, loss is: [0.49328187]\n",
      "epoch: 63, batch: 0, Auc is:0.8413422658420388, loss is: [0.5128063]\n",
      "epoch: 63, batch: 1, Auc is:0.8413150650286569, loss is: [0.5268703]\n",
      "epoch: 63, batch: 2, Auc is:0.8413094071621842, loss is: [0.5217587]\n",
      "epoch: 63, batch: 3, Auc is:0.8412982884555489, loss is: [0.5258952]\n",
      "epoch: 63, batch: 4, Auc is:0.8412614765083433, loss is: [0.5348926]\n",
      "epoch: 63, batch: 5, Auc is:0.8413074864186019, loss is: [0.50129485]\n",
      "epoch: 63, batch: 6, Auc is:0.8413219728540711, loss is: [0.5120067]\n",
      "epoch: 63, batch: 7, Auc is:0.8413446947628351, loss is: [0.5120894]\n",
      "epoch: 63, batch: 8, Auc is:0.8413994791560132, loss is: [0.49808747]\n",
      "epoch: 63, batch: 9, Auc is:0.8414469077864093, loss is: [0.49979392]\n",
      "epoch: 64, batch: 0, Auc is:0.8414845580616561, loss is: [0.50201887]\n",
      "epoch: 64, batch: 1, Auc is:0.8415082227284747, loss is: [0.51109564]\n",
      "epoch: 64, batch: 2, Auc is:0.8414956854973642, loss is: [0.52574396]\n",
      "epoch: 64, batch: 3, Auc is:0.8414976015705087, loss is: [0.5204915]\n",
      "epoch: 64, batch: 4, Auc is:0.8415313698750199, loss is: [0.50587547]\n",
      "epoch: 64, batch: 5, Auc is:0.8415540543509897, loss is: [0.50755155]\n",
      "epoch: 64, batch: 6, Auc is:0.8414731105345856, loss is: [0.5489148]\n",
      "epoch: 64, batch: 7, Auc is:0.8415123291204508, loss is: [0.50131077]\n",
      "epoch: 64, batch: 8, Auc is:0.8415268078015709, loss is: [0.5132604]\n",
      "epoch: 64, batch: 9, Auc is:0.8415566798746319, loss is: [0.50968283]\n",
      "epoch: 65, batch: 0, Auc is:0.8415675852906636, loss is: [0.5130609]\n",
      "epoch: 65, batch: 1, Auc is:0.8415525674294668, loss is: [0.5217251]\n",
      "epoch: 65, batch: 2, Auc is:0.841562406981666, loss is: [0.51420987]\n",
      "epoch: 65, batch: 3, Auc is:0.8415908337621874, loss is: [0.5079706]\n",
      "epoch: 65, batch: 4, Auc is:0.8415855251030528, loss is: [0.52642494]\n",
      "epoch: 65, batch: 5, Auc is:0.8415830505301835, loss is: [0.51851314]\n",
      "epoch: 65, batch: 6, Auc is:0.8415932471495159, loss is: [0.5151282]\n",
      "epoch: 65, batch: 7, Auc is:0.8416097396600258, loss is: [0.51277965]\n",
      "epoch: 65, batch: 8, Auc is:0.8416413177549208, loss is: [0.5048281]\n",
      "epoch: 65, batch: 9, Auc is:0.8416668975994325, loss is: [0.50918]\n",
      "epoch: 66, batch: 0, Auc is:0.8416722028026195, loss is: [0.51595813]\n",
      "epoch: 66, batch: 1, Auc is:0.841670562937613, loss is: [0.5147247]\n",
      "epoch: 66, batch: 2, Auc is:0.8416766280792058, loss is: [0.51444566]\n",
      "epoch: 66, batch: 3, Auc is:0.8417260156653684, loss is: [0.4976276]\n",
      "epoch: 66, batch: 4, Auc is:0.8416789247083006, loss is: [0.5420523]\n",
      "epoch: 66, batch: 5, Auc is:0.8416715605329754, loss is: [0.52516735]\n",
      "epoch: 66, batch: 6, Auc is:0.8417009873093168, loss is: [0.508595]\n",
      "epoch: 66, batch: 7, Auc is:0.8417573418777532, loss is: [0.49374497]\n",
      "epoch: 66, batch: 8, Auc is:0.8417773242597747, loss is: [0.50824827]\n",
      "epoch: 66, batch: 9, Auc is:0.8417756388484184, loss is: [0.5213998]\n",
      "epoch: 67, batch: 0, Auc is:0.8417805641524393, loss is: [0.51834536]\n",
      "epoch: 67, batch: 1, Auc is:0.8418081675426791, loss is: [0.5084422]\n",
      "epoch: 67, batch: 2, Auc is:0.8418286915645171, loss is: [0.5089363]\n",
      "epoch: 67, batch: 3, Auc is:0.8418637796962835, loss is: [0.50510436]\n",
      "epoch: 67, batch: 4, Auc is:0.8418746334626664, loss is: [0.512895]\n",
      "epoch: 67, batch: 5, Auc is:0.841852438610931, loss is: [0.52575976]\n",
      "epoch: 67, batch: 6, Auc is:0.8418413685576372, loss is: [0.53055894]\n",
      "epoch: 67, batch: 7, Auc is:0.8418279037725825, loss is: [0.52149904]\n",
      "epoch: 67, batch: 8, Auc is:0.8418703150300991, loss is: [0.50051016]\n",
      "epoch: 67, batch: 9, Auc is:0.8418853623197501, loss is: [0.50814605]\n",
      "epoch: 68, batch: 0, Auc is:0.841914183804053, loss is: [0.5033732]\n",
      "epoch: 68, batch: 1, Auc is:0.8418949161386018, loss is: [0.5246718]\n",
      "epoch: 68, batch: 2, Auc is:0.8418574126241035, loss is: [0.5304507]\n",
      "epoch: 68, batch: 3, Auc is:0.8418239718649918, loss is: [0.5301915]\n",
      "epoch: 68, batch: 4, Auc is:0.8418847184165854, loss is: [0.48924223]\n",
      "epoch: 68, batch: 5, Auc is:0.841888295715386, loss is: [0.5176129]\n",
      "epoch: 68, batch: 6, Auc is:0.8418830732485627, loss is: [0.5217518]\n",
      "epoch: 68, batch: 7, Auc is:0.8419231771001315, loss is: [0.5025419]\n",
      "epoch: 68, batch: 8, Auc is:0.8419489043236026, loss is: [0.5100215]\n",
      "epoch: 68, batch: 9, Auc is:0.841987737274629, loss is: [0.504018]\n",
      "epoch: 69, batch: 0, Auc is:0.8419962920863511, loss is: [0.51323175]\n",
      "epoch: 69, batch: 1, Auc is:0.8420091569639843, loss is: [0.51204777]\n",
      "epoch: 69, batch: 2, Auc is:0.8419554054786829, loss is: [0.5414261]\n",
      "epoch: 69, batch: 3, Auc is:0.8419509815145257, loss is: [0.51943743]\n",
      "epoch: 69, batch: 4, Auc is:0.8419762992580394, loss is: [0.50880134]\n",
      "epoch: 69, batch: 5, Auc is:0.8419930781375256, loss is: [0.50800526]\n",
      "epoch: 69, batch: 6, Auc is:0.8420315131833974, loss is: [0.5051632]\n",
      "epoch: 69, batch: 7, Auc is:0.8420563623310833, loss is: [0.5067324]\n",
      "epoch: 69, batch: 8, Auc is:0.8420472276398703, loss is: [0.5231516]\n",
      "epoch: 69, batch: 9, Auc is:0.84207898112918, loss is: [0.5016903]\n",
      "epoch: 70, batch: 0, Auc is:0.8420584309782945, loss is: [0.5279152]\n",
      "epoch: 70, batch: 1, Auc is:0.8421089931352574, loss is: [0.49420324]\n",
      "epoch: 70, batch: 2, Auc is:0.8420977012536729, loss is: [0.5217481]\n",
      "epoch: 70, batch: 3, Auc is:0.8420984225064359, loss is: [0.51626986]\n",
      "epoch: 70, batch: 4, Auc is:0.8420836805605686, loss is: [0.5220263]\n",
      "epoch: 70, batch: 5, Auc is:0.8421425322436347, loss is: [0.49222568]\n",
      "epoch: 70, batch: 6, Auc is:0.8421453646125041, loss is: [0.51953423]\n",
      "epoch: 70, batch: 7, Auc is:0.8421602351410256, loss is: [0.511346]\n",
      "epoch: 70, batch: 8, Auc is:0.8421554000905608, loss is: [0.5194592]\n",
      "epoch: 70, batch: 9, Auc is:0.8421776991648218, loss is: [0.5069068]\n",
      "epoch: 71, batch: 0, Auc is:0.8422299461524744, loss is: [0.4964835]\n",
      "epoch: 71, batch: 1, Auc is:0.8422392882103906, loss is: [0.51319647]\n",
      "epoch: 71, batch: 2, Auc is:0.8422161531585619, loss is: [0.53052145]\n",
      "epoch: 71, batch: 3, Auc is:0.8421959779973825, loss is: [0.52000976]\n",
      "epoch: 71, batch: 4, Auc is:0.8422605623692369, loss is: [0.48946804]\n",
      "epoch: 71, batch: 5, Auc is:0.8422702493350769, loss is: [0.5125604]\n",
      "epoch: 71, batch: 6, Auc is:0.8422586244139554, loss is: [0.5217604]\n",
      "epoch: 71, batch: 7, Auc is:0.842264657311968, loss is: [0.514499]\n",
      "epoch: 71, batch: 8, Auc is:0.8422811495879925, loss is: [0.5114961]\n",
      "epoch: 71, batch: 9, Auc is:0.8422676346254292, loss is: [0.52327144]\n",
      "epoch: 72, batch: 0, Auc is:0.8422633997913516, loss is: [0.5235974]\n",
      "epoch: 72, batch: 1, Auc is:0.8423012862154131, loss is: [0.50143766]\n",
      "epoch: 72, batch: 2, Auc is:0.8423446937730887, loss is: [0.49827912]\n",
      "epoch: 72, batch: 3, Auc is:0.8423529861646288, loss is: [0.51550645]\n",
      "epoch: 72, batch: 4, Auc is:0.8423249862660753, loss is: [0.53338134]\n",
      "epoch: 72, batch: 5, Auc is:0.8423406619200543, loss is: [0.50521266]\n",
      "epoch: 72, batch: 6, Auc is:0.8423154435962167, loss is: [0.52409685]\n",
      "epoch: 72, batch: 7, Auc is:0.8423153640963844, loss is: [0.51845944]\n",
      "epoch: 72, batch: 8, Auc is:0.8423466975882999, loss is: [0.5043411]\n",
      "epoch: 72, batch: 9, Auc is:0.842354506768056, loss is: [0.5118483]\n",
      "epoch: 73, batch: 0, Auc is:0.8423678175007144, loss is: [0.5098886]\n",
      "epoch: 73, batch: 1, Auc is:0.8423842810185462, loss is: [0.51027]\n",
      "epoch: 73, batch: 2, Auc is:0.8424023048078048, loss is: [0.5106922]\n",
      "epoch: 73, batch: 3, Auc is:0.8424021194367479, loss is: [0.51732165]\n",
      "epoch: 73, batch: 4, Auc is:0.8423881492732995, loss is: [0.5248685]\n",
      "epoch: 73, batch: 5, Auc is:0.8424185206879024, loss is: [0.5026453]\n",
      "epoch: 73, batch: 6, Auc is:0.8424449578558159, loss is: [0.5056503]\n",
      "epoch: 73, batch: 7, Auc is:0.8424668788782651, loss is: [0.507071]\n",
      "epoch: 73, batch: 8, Auc is:0.8424571484403488, loss is: [0.52041906]\n",
      "epoch: 73, batch: 9, Auc is:0.8424441595935307, loss is: [0.5184268]\n",
      "epoch: 74, batch: 0, Auc is:0.8424370220666235, loss is: [0.51980466]\n",
      "epoch: 74, batch: 1, Auc is:0.8424185977946387, loss is: [0.52312696]\n",
      "epoch: 74, batch: 2, Auc is:0.8424191544642101, loss is: [0.5147818]\n",
      "epoch: 74, batch: 3, Auc is:0.8424064540550091, loss is: [0.5193864]\n",
      "epoch: 74, batch: 4, Auc is:0.8424113002349581, loss is: [0.517941]\n",
      "epoch: 74, batch: 5, Auc is:0.8424321256300108, loss is: [0.5087471]\n",
      "epoch: 74, batch: 6, Auc is:0.842456712576108, loss is: [0.5053317]\n",
      "epoch: 74, batch: 7, Auc is:0.842477797330488, loss is: [0.506295]\n",
      "epoch: 74, batch: 8, Auc is:0.842522077784309, loss is: [0.4974409]\n",
      "epoch: 74, batch: 9, Auc is:0.8425310581828124, loss is: [0.51194346]\n",
      "epoch: 75, batch: 0, Auc is:0.8425250891055661, loss is: [0.51936275]\n",
      "epoch: 75, batch: 1, Auc is:0.8425222613933832, loss is: [0.5172588]\n",
      "epoch: 75, batch: 2, Auc is:0.8425550715044755, loss is: [0.50055665]\n",
      "epoch: 75, batch: 3, Auc is:0.8426020756055753, loss is: [0.4934002]\n",
      "epoch: 75, batch: 4, Auc is:0.8425830608480901, loss is: [0.5248211]\n",
      "epoch: 75, batch: 5, Auc is:0.8425879356674855, loss is: [0.5175013]\n",
      "epoch: 75, batch: 6, Auc is:0.8425773066311747, loss is: [0.5200143]\n",
      "epoch: 75, batch: 7, Auc is:0.8426018961779511, loss is: [0.5036364]\n",
      "epoch: 75, batch: 8, Auc is:0.842611008281628, loss is: [0.51467776]\n",
      "epoch: 75, batch: 9, Auc is:0.8426213286344572, loss is: [0.51308185]\n",
      "epoch: 76, batch: 0, Auc is:0.8425974246652316, loss is: [0.52457505]\n",
      "epoch: 76, batch: 1, Auc is:0.8426068174944479, loss is: [0.5095672]\n",
      "epoch: 76, batch: 2, Auc is:0.8426276941095736, loss is: [0.5072513]\n",
      "epoch: 76, batch: 3, Auc is:0.842613664659467, loss is: [0.5203842]\n",
      "epoch: 76, batch: 4, Auc is:0.8426048971163713, loss is: [0.5180149]\n",
      "epoch: 76, batch: 5, Auc is:0.8426497731602982, loss is: [0.49684954]\n",
      "epoch: 76, batch: 6, Auc is:0.8426648358236912, loss is: [0.5086598]\n",
      "epoch: 76, batch: 7, Auc is:0.8426650327713576, loss is: [0.5142711]\n",
      "epoch: 76, batch: 8, Auc is:0.8426917472179893, loss is: [0.50514585]\n",
      "epoch: 76, batch: 9, Auc is:0.8427005421800811, loss is: [0.519613]\n",
      "epoch: 77, batch: 0, Auc is:0.8427319278377227, loss is: [0.49922985]\n",
      "epoch: 77, batch: 1, Auc is:0.8427233465924947, loss is: [0.52300596]\n",
      "epoch: 77, batch: 2, Auc is:0.8427456419168314, loss is: [0.5073142]\n",
      "epoch: 77, batch: 3, Auc is:0.8427280718087392, loss is: [0.52796435]\n",
      "epoch: 77, batch: 4, Auc is:0.842728098311299, loss is: [0.5177775]\n",
      "epoch: 77, batch: 5, Auc is:0.8427443520827304, loss is: [0.5097147]\n",
      "epoch: 77, batch: 6, Auc is:0.8427684717494279, loss is: [0.5044937]\n",
      "epoch: 77, batch: 7, Auc is:0.8427823845848882, loss is: [0.5092579]\n",
      "epoch: 77, batch: 8, Auc is:0.8427779016383335, loss is: [0.5160808]\n",
      "epoch: 77, batch: 9, Auc is:0.8427776957088526, loss is: [0.51174474]\n",
      "epoch: 78, batch: 0, Auc is:0.8428052704674585, loss is: [0.50625384]\n",
      "epoch: 78, batch: 1, Auc is:0.8427844909026448, loss is: [0.5244956]\n",
      "epoch: 78, batch: 2, Auc is:0.8428009585450668, loss is: [0.50800073]\n",
      "epoch: 78, batch: 3, Auc is:0.8428017508980225, loss is: [0.51279855]\n",
      "epoch: 78, batch: 4, Auc is:0.8428355248772228, loss is: [0.5034077]\n",
      "epoch: 78, batch: 5, Auc is:0.8428264984855668, loss is: [0.52077734]\n",
      "epoch: 78, batch: 6, Auc is:0.8428234143634311, loss is: [0.5157031]\n",
      "epoch: 78, batch: 7, Auc is:0.8428472190815404, loss is: [0.5016227]\n",
      "epoch: 78, batch: 8, Auc is:0.8428318614286029, loss is: [0.5230165]\n",
      "epoch: 78, batch: 9, Auc is:0.8428475893192768, loss is: [0.505724]\n",
      "epoch: 79, batch: 0, Auc is:0.842853235743782, loss is: [0.51259583]\n",
      "epoch: 79, batch: 1, Auc is:0.8428452266756029, loss is: [0.52275956]\n",
      "epoch: 79, batch: 2, Auc is:0.842821123084754, loss is: [0.5259853]\n",
      "epoch: 79, batch: 3, Auc is:0.8428527169372029, loss is: [0.49907768]\n",
      "epoch: 79, batch: 4, Auc is:0.8428644144423184, loss is: [0.51235455]\n",
      "epoch: 79, batch: 5, Auc is:0.8428981984412544, loss is: [0.50162745]\n",
      "epoch: 79, batch: 6, Auc is:0.8429512617829059, loss is: [0.49103877]\n",
      "epoch: 79, batch: 7, Auc is:0.8429503320752777, loss is: [0.5205373]\n",
      "epoch: 79, batch: 8, Auc is:0.8429245967786027, loss is: [0.5227611]\n",
      "epoch: 79, batch: 9, Auc is:0.8429226959305479, loss is: [0.5136504]\n",
      "epoch: 80, batch: 0, Auc is:0.8429461019991442, loss is: [0.5091969]\n",
      "epoch: 80, batch: 1, Auc is:0.8429544818194072, loss is: [0.5149489]\n",
      "epoch: 80, batch: 2, Auc is:0.84297474319378, loss is: [0.5049002]\n",
      "epoch: 80, batch: 3, Auc is:0.8429370418960233, loss is: [0.5346308]\n",
      "epoch: 80, batch: 4, Auc is:0.8429521687534096, loss is: [0.5091619]\n",
      "epoch: 80, batch: 5, Auc is:0.8429400167432279, loss is: [0.52283335]\n",
      "epoch: 80, batch: 6, Auc is:0.8429861035450817, loss is: [0.49181154]\n",
      "epoch: 80, batch: 7, Auc is:0.8429937778646777, loss is: [0.5059789]\n",
      "epoch: 80, batch: 8, Auc is:0.8430112583375453, loss is: [0.50577164]\n",
      "epoch: 80, batch: 9, Auc is:0.8429968103758071, loss is: [0.5200343]\n",
      "epoch: 81, batch: 0, Auc is:0.8430130144602291, loss is: [0.50588214]\n",
      "epoch: 81, batch: 1, Auc is:0.8429958497376903, loss is: [0.52533054]\n",
      "epoch: 81, batch: 2, Auc is:0.8429945579444977, loss is: [0.5142094]\n",
      "epoch: 81, batch: 3, Auc is:0.8429852198599465, loss is: [0.51841825]\n",
      "epoch: 81, batch: 4, Auc is:0.8430091454673135, loss is: [0.5038097]\n",
      "epoch: 81, batch: 5, Auc is:0.8430237064756384, loss is: [0.50975895]\n",
      "epoch: 81, batch: 6, Auc is:0.8430462764002928, loss is: [0.5062409]\n",
      "epoch: 81, batch: 7, Auc is:0.8430428291201721, loss is: [0.5121991]\n",
      "epoch: 81, batch: 8, Auc is:0.8430734801372584, loss is: [0.5030903]\n",
      "epoch: 81, batch: 9, Auc is:0.843059919586177, loss is: [0.52072597]\n",
      "epoch: 82, batch: 0, Auc is:0.8430702243185645, loss is: [0.51184404]\n",
      "epoch: 82, batch: 1, Auc is:0.8430497720602169, loss is: [0.5236889]\n",
      "epoch: 82, batch: 2, Auc is:0.8430884384548752, loss is: [0.49496326]\n",
      "epoch: 82, batch: 3, Auc is:0.8430813899536804, loss is: [0.5232444]\n",
      "epoch: 82, batch: 4, Auc is:0.8430849691613516, loss is: [0.5163915]\n",
      "epoch: 82, batch: 5, Auc is:0.8431278296719703, loss is: [0.49457768]\n",
      "epoch: 82, batch: 6, Auc is:0.8431283906237389, loss is: [0.515304]\n",
      "epoch: 82, batch: 7, Auc is:0.8431353275055373, loss is: [0.506744]\n",
      "epoch: 82, batch: 8, Auc is:0.8431462115517685, loss is: [0.50768584]\n",
      "epoch: 82, batch: 9, Auc is:0.8431339188050452, loss is: [0.51891637]\n",
      "epoch: 83, batch: 0, Auc is:0.8431727869644782, loss is: [0.49268654]\n",
      "epoch: 83, batch: 1, Auc is:0.8431919953535278, loss is: [0.5054726]\n",
      "epoch: 83, batch: 2, Auc is:0.8431823567505394, loss is: [0.5227664]\n",
      "epoch: 83, batch: 3, Auc is:0.8432020802814548, loss is: [0.5048915]\n",
      "epoch: 83, batch: 4, Auc is:0.8432386118990949, loss is: [0.4980285]\n",
      "epoch: 83, batch: 5, Auc is:0.8432386690827245, loss is: [0.5139244]\n",
      "epoch: 83, batch: 6, Auc is:0.8432288327201483, loss is: [0.5206938]\n",
      "epoch: 83, batch: 7, Auc is:0.8432080736878775, loss is: [0.52200717]\n",
      "epoch: 83, batch: 8, Auc is:0.8432033917469678, loss is: [0.51867753]\n",
      "epoch: 83, batch: 9, Auc is:0.8432054816565411, loss is: [0.51282257]\n",
      "epoch: 84, batch: 0, Auc is:0.8432219668599595, loss is: [0.50369847]\n",
      "epoch: 84, batch: 1, Auc is:0.8432346014908372, loss is: [0.50522065]\n",
      "epoch: 84, batch: 2, Auc is:0.8432310024472705, loss is: [0.5142587]\n",
      "epoch: 84, batch: 3, Auc is:0.8432182876504517, loss is: [0.52021617]\n",
      "epoch: 84, batch: 4, Auc is:0.8432245527607792, loss is: [0.5131462]\n",
      "epoch: 84, batch: 5, Auc is:0.8432370684849098, loss is: [0.50885326]\n",
      "epoch: 84, batch: 6, Auc is:0.8432551142276109, loss is: [0.50698125]\n",
      "epoch: 84, batch: 7, Auc is:0.8432746978599306, loss is: [0.50795084]\n",
      "epoch: 84, batch: 8, Auc is:0.8432773647200557, loss is: [0.5115764]\n",
      "epoch: 84, batch: 9, Auc is:0.8432684305414547, loss is: [0.5203169]\n",
      "epoch: 85, batch: 0, Auc is:0.8432721040122109, loss is: [0.514404]\n",
      "epoch: 85, batch: 1, Auc is:0.8433000129270349, loss is: [0.4988145]\n",
      "epoch: 85, batch: 2, Auc is:0.8433150963465588, loss is: [0.5081432]\n",
      "epoch: 85, batch: 3, Auc is:0.8433470396248793, loss is: [0.4960948]\n",
      "epoch: 85, batch: 4, Auc is:0.8433420229516997, loss is: [0.51915574]\n",
      "epoch: 85, batch: 5, Auc is:0.8433440039257908, loss is: [0.51418346]\n",
      "epoch: 85, batch: 6, Auc is:0.8433233231174985, loss is: [0.5298639]\n",
      "epoch: 85, batch: 7, Auc is:0.8433221456273866, loss is: [0.51470053]\n",
      "epoch: 85, batch: 8, Auc is:0.8433135526523782, loss is: [0.5168718]\n",
      "epoch: 85, batch: 9, Auc is:0.8433329484327549, loss is: [0.50153816]\n",
      "epoch: 86, batch: 0, Auc is:0.8433699215348653, loss is: [0.49447715]\n",
      "epoch: 86, batch: 1, Auc is:0.8433709432340015, loss is: [0.518686]\n",
      "epoch: 86, batch: 2, Auc is:0.8433976295874893, loss is: [0.49918345]\n",
      "epoch: 86, batch: 3, Auc is:0.8434096461208624, loss is: [0.5109772]\n",
      "epoch: 86, batch: 4, Auc is:0.8433876256190497, loss is: [0.52001375]\n",
      "epoch: 86, batch: 5, Auc is:0.8434070923777708, loss is: [0.50596106]\n",
      "epoch: 86, batch: 6, Auc is:0.8433988764686451, loss is: [0.5154919]\n",
      "epoch: 86, batch: 7, Auc is:0.8433923122272599, loss is: [0.5193115]\n",
      "epoch: 86, batch: 8, Auc is:0.8434109423774111, loss is: [0.5041462]\n",
      "epoch: 86, batch: 9, Auc is:0.843397568432804, loss is: [0.52133423]\n",
      "epoch: 87, batch: 0, Auc is:0.843421257173162, loss is: [0.5001902]\n",
      "epoch: 87, batch: 1, Auc is:0.8434205211072949, loss is: [0.51396024]\n",
      "epoch: 87, batch: 2, Auc is:0.8434152879671507, loss is: [0.5198512]\n",
      "epoch: 87, batch: 3, Auc is:0.843386428298847, loss is: [0.5303438]\n",
      "epoch: 87, batch: 4, Auc is:0.8433610293127274, loss is: [0.529913]\n",
      "epoch: 87, batch: 5, Auc is:0.8434069202482505, loss is: [0.48889387]\n",
      "epoch: 87, batch: 6, Auc is:0.8434094411614028, loss is: [0.51342475]\n",
      "epoch: 87, batch: 7, Auc is:0.8434142163745022, loss is: [0.50942755]\n",
      "epoch: 87, batch: 8, Auc is:0.8434539266178569, loss is: [0.49384317]\n",
      "epoch: 87, batch: 9, Auc is:0.8434615062383396, loss is: [0.5086429]\n",
      "epoch: 88, batch: 0, Auc is:0.8434516104548262, loss is: [0.51966363]\n",
      "epoch: 88, batch: 1, Auc is:0.8434934359754722, loss is: [0.485587]\n",
      "epoch: 88, batch: 2, Auc is:0.843512458921486, loss is: [0.50161964]\n",
      "epoch: 88, batch: 3, Auc is:0.8434871456196377, loss is: [0.52606887]\n",
      "epoch: 88, batch: 4, Auc is:0.8434858748826642, loss is: [0.5153872]\n",
      "epoch: 88, batch: 5, Auc is:0.8435115136610589, loss is: [0.4995334]\n",
      "epoch: 88, batch: 6, Auc is:0.8435153287095973, loss is: [0.5165485]\n",
      "epoch: 88, batch: 7, Auc is:0.8435226106931686, loss is: [0.5123172]\n",
      "epoch: 88, batch: 8, Auc is:0.8435135975163501, loss is: [0.5218975]\n",
      "epoch: 88, batch: 9, Auc is:0.8435234369516804, loss is: [0.50724566]\n",
      "epoch: 89, batch: 0, Auc is:0.8435224152993698, loss is: [0.5143202]\n",
      "epoch: 89, batch: 1, Auc is:0.8435463785789182, loss is: [0.504004]\n",
      "epoch: 89, batch: 2, Auc is:0.8435268327948577, loss is: [0.5264724]\n",
      "epoch: 89, batch: 3, Auc is:0.8435349562776441, loss is: [0.5081157]\n",
      "epoch: 89, batch: 4, Auc is:0.8434945357542042, loss is: [0.5315808]\n",
      "epoch: 89, batch: 5, Auc is:0.8435321426804404, loss is: [0.49121243]\n",
      "epoch: 89, batch: 6, Auc is:0.8435636400700719, loss is: [0.49747077]\n",
      "epoch: 89, batch: 7, Auc is:0.8435692869063794, loss is: [0.50996196]\n",
      "epoch: 89, batch: 8, Auc is:0.8435896895218403, loss is: [0.50295]\n",
      "epoch: 89, batch: 9, Auc is:0.8435847625841268, loss is: [0.5186008]\n",
      "epoch: 90, batch: 0, Auc is:0.8435736682850988, loss is: [0.52391946]\n",
      "epoch: 90, batch: 1, Auc is:0.843565719404145, loss is: [0.5192951]\n",
      "epoch: 90, batch: 2, Auc is:0.8435787184299885, loss is: [0.50580835]\n",
      "epoch: 90, batch: 3, Auc is:0.8435794741356286, loss is: [0.5103154]\n",
      "epoch: 90, batch: 4, Auc is:0.8436070684967565, loss is: [0.50042695]\n",
      "epoch: 90, batch: 5, Auc is:0.8436346639764336, loss is: [0.4976148]\n",
      "epoch: 90, batch: 6, Auc is:0.8436217302075212, loss is: [0.5196036]\n",
      "epoch: 90, batch: 7, Auc is:0.8435976580483372, loss is: [0.526157]\n",
      "epoch: 90, batch: 8, Auc is:0.8436168227367205, loss is: [0.5019395]\n",
      "epoch: 90, batch: 9, Auc is:0.8436437520910574, loss is: [0.49971145]\n",
      "epoch: 91, batch: 0, Auc is:0.8436712634155951, loss is: [0.49744877]\n",
      "epoch: 91, batch: 1, Auc is:0.8437013116221554, loss is: [0.4954032]\n",
      "epoch: 91, batch: 2, Auc is:0.843656935815043, loss is: [0.5371844]\n",
      "epoch: 91, batch: 3, Auc is:0.8437018060777852, loss is: [0.48917362]\n",
      "epoch: 91, batch: 4, Auc is:0.8436766115452978, loss is: [0.53063565]\n",
      "epoch: 91, batch: 5, Auc is:0.8436969435178153, loss is: [0.50359064]\n",
      "epoch: 91, batch: 6, Auc is:0.8437182873409773, loss is: [0.50374544]\n",
      "epoch: 91, batch: 7, Auc is:0.8437321832768668, loss is: [0.5028469]\n",
      "epoch: 91, batch: 8, Auc is:0.8437175131069721, loss is: [0.5228098]\n",
      "epoch: 91, batch: 9, Auc is:0.8436962335210233, loss is: [0.5260424]\n",
      "epoch: 92, batch: 0, Auc is:0.8436762520049, loss is: [0.5278734]\n",
      "epoch: 92, batch: 1, Auc is:0.8436927327325331, loss is: [0.5077374]\n",
      "epoch: 92, batch: 2, Auc is:0.8437267647185869, loss is: [0.49447826]\n",
      "epoch: 92, batch: 3, Auc is:0.8437432730624443, loss is: [0.5041966]\n",
      "epoch: 92, batch: 4, Auc is:0.8437264620614838, loss is: [0.5183793]\n",
      "epoch: 92, batch: 5, Auc is:0.8437421965302743, loss is: [0.50253373]\n",
      "epoch: 92, batch: 6, Auc is:0.8437497739582399, loss is: [0.50988096]\n",
      "epoch: 92, batch: 7, Auc is:0.8437531950117044, loss is: [0.511849]\n",
      "epoch: 92, batch: 8, Auc is:0.8437502769631363, loss is: [0.51481235]\n",
      "epoch: 92, batch: 9, Auc is:0.843751159290093, loss is: [0.51282114]\n",
      "epoch: 93, batch: 0, Auc is:0.8437353579625846, loss is: [0.5193224]\n",
      "epoch: 93, batch: 1, Auc is:0.8437471192393621, loss is: [0.5033938]\n",
      "epoch: 93, batch: 2, Auc is:0.84372291271037, loss is: [0.52780837]\n",
      "epoch: 93, batch: 3, Auc is:0.843726721805974, loss is: [0.5108663]\n",
      "epoch: 93, batch: 4, Auc is:0.8437145424111467, loss is: [0.5245396]\n",
      "epoch: 93, batch: 5, Auc is:0.8437221304008925, loss is: [0.5111616]\n",
      "epoch: 93, batch: 6, Auc is:0.8437541260257017, loss is: [0.49813205]\n",
      "epoch: 93, batch: 7, Auc is:0.8437827777379736, loss is: [0.4963162]\n",
      "epoch: 93, batch: 8, Auc is:0.8437817455773597, loss is: [0.5090545]\n",
      "epoch: 93, batch: 9, Auc is:0.8438056684398247, loss is: [0.5000885]\n",
      "epoch: 94, batch: 0, Auc is:0.8438084620273287, loss is: [0.5151688]\n",
      "epoch: 94, batch: 1, Auc is:0.843810982803093, loss is: [0.5119394]\n",
      "epoch: 94, batch: 2, Auc is:0.8437953912437984, loss is: [0.5226523]\n",
      "epoch: 94, batch: 3, Auc is:0.8438081959929921, loss is: [0.5070386]\n",
      "epoch: 94, batch: 4, Auc is:0.8438225749658679, loss is: [0.5098201]\n",
      "epoch: 94, batch: 5, Auc is:0.8438158595391116, loss is: [0.51725227]\n",
      "epoch: 94, batch: 6, Auc is:0.8438301014431305, loss is: [0.5011183]\n",
      "epoch: 94, batch: 7, Auc is:0.8438654074788332, loss is: [0.49089733]\n",
      "epoch: 94, batch: 8, Auc is:0.8438847616681301, loss is: [0.49868792]\n",
      "epoch: 94, batch: 9, Auc is:0.8438625439152596, loss is: [0.52588147]\n",
      "epoch: 95, batch: 0, Auc is:0.8438778268303235, loss is: [0.51078874]\n",
      "epoch: 95, batch: 1, Auc is:0.8438833196762726, loss is: [0.51184195]\n",
      "epoch: 95, batch: 2, Auc is:0.8439079759791526, loss is: [0.4985419]\n",
      "epoch: 95, batch: 3, Auc is:0.8438856993517141, loss is: [0.53403246]\n",
      "epoch: 95, batch: 4, Auc is:0.8438831342056696, loss is: [0.5044285]\n",
      "epoch: 95, batch: 5, Auc is:0.8438777196008128, loss is: [0.51705664]\n",
      "epoch: 95, batch: 6, Auc is:0.8439027803411483, loss is: [0.4917604]\n",
      "epoch: 95, batch: 7, Auc is:0.8438804006632239, loss is: [0.5224494]\n",
      "epoch: 95, batch: 8, Auc is:0.8438945449772904, loss is: [0.5076759]\n",
      "epoch: 95, batch: 9, Auc is:0.8439154265846527, loss is: [0.5001521]\n",
      "epoch: 96, batch: 0, Auc is:0.8439515414419119, loss is: [0.49017832]\n",
      "epoch: 96, batch: 1, Auc is:0.8439470638743238, loss is: [0.51568204]\n",
      "epoch: 96, batch: 2, Auc is:0.8439657162175459, loss is: [0.5022269]\n",
      "epoch: 96, batch: 3, Auc is:0.8439332028239318, loss is: [0.5381718]\n",
      "epoch: 96, batch: 4, Auc is:0.8439634091160136, loss is: [0.4969225]\n",
      "epoch: 96, batch: 5, Auc is:0.8439328451417069, loss is: [0.52799875]\n",
      "epoch: 96, batch: 6, Auc is:0.8439373339469664, loss is: [0.50987935]\n",
      "epoch: 96, batch: 7, Auc is:0.843922924738667, loss is: [0.5232973]\n",
      "epoch: 96, batch: 8, Auc is:0.8439240826812048, loss is: [0.50859004]\n",
      "epoch: 96, batch: 9, Auc is:0.8439729009664888, loss is: [0.48334146]\n",
      "epoch: 97, batch: 0, Auc is:0.84397431500748, loss is: [0.5151534]\n",
      "epoch: 97, batch: 1, Auc is:0.8440032515894076, loss is: [0.4914867]\n",
      "epoch: 97, batch: 2, Auc is:0.8440208888654865, loss is: [0.50555676]\n",
      "epoch: 97, batch: 3, Auc is:0.844042675946438, loss is: [0.4988498]\n",
      "epoch: 97, batch: 4, Auc is:0.8440571500225209, loss is: [0.5024263]\n",
      "epoch: 97, batch: 5, Auc is:0.8440816532490506, loss is: [0.4994773]\n",
      "epoch: 97, batch: 6, Auc is:0.844054248935095, loss is: [0.5306219]\n",
      "epoch: 97, batch: 7, Auc is:0.8440583542325913, loss is: [0.51139385]\n",
      "epoch: 97, batch: 8, Auc is:0.8440179490312196, loss is: [0.5376458]\n",
      "epoch: 97, batch: 9, Auc is:0.8440223746453522, loss is: [0.5061575]\n",
      "epoch: 98, batch: 0, Auc is:0.8440458773846834, loss is: [0.50172275]\n",
      "epoch: 98, batch: 1, Auc is:0.8440513877673832, loss is: [0.5087184]\n",
      "epoch: 98, batch: 2, Auc is:0.8440564830066408, loss is: [0.5097472]\n",
      "epoch: 98, batch: 3, Auc is:0.8440526656564663, loss is: [0.51355666]\n",
      "epoch: 98, batch: 4, Auc is:0.8440317541503697, loss is: [0.52333677]\n",
      "epoch: 98, batch: 5, Auc is:0.8440428090108425, loss is: [0.50939316]\n",
      "epoch: 98, batch: 6, Auc is:0.8440519601688585, loss is: [0.50955355]\n",
      "epoch: 98, batch: 7, Auc is:0.8440596769270028, loss is: [0.5064818]\n",
      "epoch: 98, batch: 8, Auc is:0.8440519467731155, loss is: [0.52121407]\n",
      "epoch: 98, batch: 9, Auc is:0.8440785322837804, loss is: [0.49137112]\n",
      "epoch: 99, batch: 0, Auc is:0.8440668832044813, loss is: [0.51428246]\n",
      "epoch: 99, batch: 1, Auc is:0.844028399401126, loss is: [0.5408633]\n",
      "epoch: 99, batch: 2, Auc is:0.8440526053462686, loss is: [0.496665]\n",
      "epoch: 99, batch: 3, Auc is:0.8440388487297925, loss is: [0.5234782]\n",
      "epoch: 99, batch: 4, Auc is:0.8440555013380243, loss is: [0.50026494]\n",
      "epoch: 99, batch: 5, Auc is:0.8440699003908064, loss is: [0.5014308]\n",
      "epoch: 99, batch: 6, Auc is:0.844108951825, loss is: [0.48905167]\n",
      "epoch: 99, batch: 7, Auc is:0.8440965535146308, loss is: [0.5221559]\n",
      "epoch: 99, batch: 8, Auc is:0.8441205007576816, loss is: [0.49722168]\n",
      "epoch: 99, batch: 9, Auc is:0.8441290156549975, loss is: [0.5096443]\n"
     ]
    }
   ],
   "source": [
    "# 构造模型\n",
    "model = MyNet()\n",
    "# model_dict = paddle.load('model.pdparams')\n",
    "# model.set_dict(model_dict)\n",
    "model.train()\n",
    "max_epoch=100\n",
    "opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())\n",
    "\n",
    "# paddle.metric 评估指标计算相关的API，包括 Accuracy, Auc等\n",
    "\n",
    "# 训练\n",
    "now_step=0\n",
    "# 最小的loss\n",
    "minLoss = 0.48\n",
    "# 最大的Auc\n",
    "maxAuc = 0.843\n",
    "m = paddle.metric.Auc()\n",
    "for epoch in range(max_epoch):\n",
    "    for step, data in enumerate(train_dataloader):\n",
    "        now_step+=1\n",
    "\n",
    "        data,emb_data, label = data\n",
    "        pre = model(data,emb_data)\n",
    "        \n",
    "        #print(pre.shape)\n",
    "        loss = paddle.nn.functional.cross_entropy(pre,label,weight=paddle.to_tensor([0.2,1.0]),reduction='mean')\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.clear_gradients()\n",
    "        \n",
    "        if now_step%1==0:\n",
    "            if minLoss > loss.mean():\n",
    "                minLoss = loss.mean().numpy()\n",
    "                paddle.save(model.state_dict(), 'model/modelMinLoss_mynet_{}.pdparams'.format(minLoss))\n",
    "\n",
    "            m.update(preds=pre, labels=label)\n",
    "            resAccumulate = m.accumulate()\n",
    "            if maxAuc < resAccumulate:\n",
    "                maxAuc = resAccumulate\n",
    "                paddle.save(model.state_dict(), 'model/modelmaxAuc_mynet_{}.pdparams'.format(maxAuc))\n",
    "            print(\"epoch: {}, batch: {}, Auc is:{}, loss is: {}\".format(epoch, step, resAccumulate,loss.mean().numpy()))\n",
    "        \n",
    "\n",
    "# 保存模型到model.pdparams\n",
    "paddle.save(model.state_dict(), 'modelM_mynet.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T08:20:52.883847Z",
     "iopub.status.busy": "2022-11-11T08:20:52.883430Z",
     "iopub.status.idle": "2022-11-11T08:20:52.888227Z",
     "shell.execute_reply": "2022-11-11T08:20:52.887543Z",
     "shell.execute_reply.started": "2022-11-11T08:20:52.883818Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "# # 构造模型\n",
    "# model = MyNet()\n",
    "\n",
    "# # model_dict = paddle.load('model.pdparams')\n",
    "# # model.set_dict(model_dict)\n",
    "\n",
    "# model.train()\n",
    "\n",
    "# max_epoch=15\n",
    "# # 定义优化算法，使用随机梯度下降SGD\n",
    "# opt = paddle.optimizer.SGD(learning_rate=0.15, parameters=model.parameters())\n",
    "\n",
    "# # 训练\n",
    "# now_step=0\n",
    "# for epoch in range(max_epoch):\n",
    "#     for step, data in enumerate(train_dataloader):\n",
    "#         now_step+=1\n",
    "\n",
    "#         data,emb_data, label = data\n",
    "#         pre = model(data,emb_data)\n",
    "#         # binary_cross_entropy\n",
    "#         loss = paddle.nn.functional.cross_entropy                                      \n",
    "#         # loss = paddle.nn.functional.square_error_cost(pre,label.reshape([-1,1]).astype('float32'))\n",
    "#         # loss = paddle.mean(loss)\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         opt.clear_gradients()\n",
    "#         if now_step%1==0:\n",
    "#             print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch, step, loss.mean().numpy()))\n",
    "\n",
    "# # 保存模型到model.pdparams\n",
    "# paddle.save(model.state_dict(), 'model.pdparams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T08:21:47.984853Z",
     "iopub.status.busy": "2022-11-11T08:21:47.984295Z",
     "iopub.status.idle": "2022-11-11T08:21:48.242509Z",
     "shell.execute_reply": "2022-11-11T08:21:48.241308Z",
     "shell.execute_reply.started": "2022-11-11T08:21:47.984821Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 读取模型和构造读取器\n",
    "model = MyNet()\n",
    "\n",
    "# model_dict = paddle.load('/home/aistudio/model/modelMinLoss_mynet_[0.47939792].pdparams')\n",
    "# model_dict = paddle.load('/home/aistudio/model/modelmaxAuc_mynet_0.8430892418873612.pdparams')\n",
    "model_dict = paddle.load('/home/aistudio/model/modelmaxAuc_mynet_0.844108951825.pdparams')\n",
    "\n",
    "model.set_dict(model_dict)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_dataset=MyDateset('data/data130187/test_public.csv',mode = 'test')\n",
    "\n",
    "test_dataloader = paddle.io.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T08:20:53.139072Z",
     "iopub.status.busy": "2022-11-11T08:20:53.138765Z",
     "iopub.status.idle": "2022-11-11T08:20:53.143126Z",
     "shell.execute_reply": "2022-11-11T08:20:53.142327Z",
     "shell.execute_reply.started": "2022-11-11T08:20:53.139046Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 将结果保存在result.csv中\n",
    "# result = []\n",
    "# for step, data in enumerate(test_dataloader):\n",
    "#     data ,emb_data, loan_id = data\n",
    "#     pre = model(data,emb_data)\n",
    "#     result.append([loan_id.numpy()[0], pre[:,1].numpy()[0]])\n",
    "#     # result.append([loan_id.numpy()[0], np.argmax(pre.numpy())])\n",
    "\n",
    "# pd.DataFrame(result,columns=['id','isDefault']).to_csv('result.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T08:21:51.838837Z",
     "iopub.status.busy": "2022-11-11T08:21:51.837778Z",
     "iopub.status.idle": "2022-11-11T08:22:07.959713Z",
     "shell.execute_reply": "2022-11-11T08:22:07.958691Z",
     "shell.execute_reply.started": "2022-11-11T08:21:51.838757Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for step, data in enumerate(test_dataloader):\n",
    "    data ,emb_data, loan_id = data\n",
    "    pre = model(data,emb_data)\n",
    "    preRes = 0\n",
    "    if pre[:,1].numpy()[0] >0.3:\n",
    "        preRes = 1\n",
    "    result.append([loan_id.numpy()[0], pre[:,1].numpy()[0]])\n",
    "\n",
    "pd.DataFrame(result,columns=['id','isDefault']).to_csv('result.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
